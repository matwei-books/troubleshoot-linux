
## perl {#sec-lokal-werkzeuge-perl}

Zwischen den vielen Spezialwerkzeugen für die Fehlersuche und der Shell als
Kommandozentrale benötige ich hin und wieder ein Werkzeug, mit dem sich auch
kniffligere Probleme angehen lassen, die so vielleicht vorher noch gar nicht
untersucht worden sind. Etwas, das sich etwa so schnell wie die Shell
programmieren läßt, aber ausdrucksstärker ist und auch sehr komplexe
Probleme angehen kann. Für mich ist das Perl. Für andere vielleicht Python,
das in vielem Perl ähnlich nicht, aber auf keinem Fall in der Syntax.

Die Programmiersprache Perl umfasst Konzepte von einfachen Werkzeugen wie sed
oder awk bis hin zu anspruchsvollen Programmiersprachen wie C oder Lisp. Es
gibt umfangreiche Fachliteratur sowohl offline als auch online sowie
Communities, an die man sich bei Problemen wenden kann.

Was Perl aber heraushebt gegenüber vielen anderen Skriptsprachen ist CPAN,
das Comprehensive Perl Archive Network, ein so umfangreiches Reservoir an
Softwaremodulen für fast alle erdenklichen Zwecke, das es möglich macht, die
meisten Skripts auf wenige Zeilen zu beschränken. Die besten und meist
verwendeten Module schaffen es mit der Zeit in die Standarddistribution und
stehen dann nach der Installation von Perl gleich zur Verfügung. In vielen
Fällen muß Perl auch gar nicht installiert werden, weil es bereits
Bestandteil des Systems ist.

Ganz besonders hilfreich bei der Problemlösung mit Perl ist das Perl
Kochbuch von Tom Christiansen und Nathan Torkington
[CT2000](#bib-ct2000). In diesem sind Lösungen
für viele Probleme in Rezeptform aufbereitet und vor allen Dingen erläutert.
Die Codebeispiele aus dem Kochbuch sind Online verfügbar, den meisten Wert
zieht man jedoch aus den Erläuterungen im Buch.

### Syslog auswerten

Es kommt immer mal wieder, dass ich die Zeilen in den Systemprotokollen
miteinander verknüpfen muss, um eine ganz spezielle Auswertung zu bekommen.
Finde ich kein geeignetes Programm, beginne ich mit folgendem Fragment, dass
ich dann für die Lösung meines konkreten Problems ausbaue:
  
<<[read-syslog.pl](code/read-syslog.pl)

In Zeile 3 gebe ich den Prozess an, an dessen Logzeilen ich interessiert
bin. Sind es mehrere Prozesse, muss ich gegebenenfalls die Zeile 21
anpassen.

Die Zeilen 4-13 definieren einen regulären Ausdruck mit dessen Hilfe ich
die Protokollzeilen aufspalte in die angegebenen Bestandteile.

Die Zeitfelder fasse ich in der Funktion `utctime()` zu einer Zahl
zusammen. Als Jahr nimmt das Skript das aktuelle an, dieses wird in zeile 14
ermittelt.

In Funktion `process_line()` kann ich die gesamte
Auswertelogik für die Protokollzeilen schreiben und dabei auf die bereits
separierten allgemeinen Felder und die eigentliche Nachricht zurückgreifen.

## fuser {#sec-lokal-werkzeuge-fuser}

Das Programm fuser setzte ich ein, wenn ich schnell Informationen darüber
haben will, welche Prozesse bestimmte Dateien oder Netzwerksockets geöffnet
haben, um sie dann mit anderen Programmen näher zu untersuchen.
Zwar kann ich die ermittelten Prozesse dann gleich von fuser beenden lassen,
aber in diesem Buch geht es vor allem um die Fehleranalyse und dafür wäre
das dann meist doch etwas zu grobschlächtig.

Was mich vor allem interessiert, sind die Prozesse und die Art und Weise,
wie diese die betreffenden Dateien verwenden.
Diese bekomme ich von fuser in einer Tabelle angezeigt. In der ersten Spalte
steht die Datei, dahinter die PID. Mit der Option -v kann ich diese Ausgabe
erweitern, so dass fuser für jeden Prozess den Benutzer (USER), die PID, den
Zugriff (ACCESS) und den Namen des Prozesses (COMMAND) anzeigt.

Von diesen ist ACCESS für viele Analysen interessant. Diese Spalte kann die
folgenden Merkmale haben:

*c*
: CWD, das Arbeitsverzeichnis des Prozesses,

*e*
: Executable, die Datei wird als Programm ausgeführt

*f*
: File, die Datei ist als normale Datei geöffnet

*F*
: File, die Datei ist zum Schreiben geöffnet

*r*
: Root, die Datei ist Wurzelverzeichnis

*m*
: MMAP, die Datei ist in den Speicherbereich des Prozesses
eingeblendet (zum Beispiel als Bibliothek)

Mit diesen Merkmalen bekomme ich heraus, wie ein Prozess eine Datei
verwendet. Allerdings kann ich das nur für Dateien sehen, die noch im
Dateisystem verlinkt sind. Dateien, die zwar geöffnet, aber nicht mehr im
Dateisystem verlinkt sind, kann ich damit nicht finden. Dazu benötige ich
andere Programme, wie zum Beispiel lsof. Mit der Option `--mount`
(`-m`) bekomme ich aber zumindest die PID dieser Prozesse, und kann
diese dann mit lsof näher untersuchen.

Dazu muss ich folgende Besonderheit der Ausgabe von fuser beachten. Das
Programm schreibt nur die PIDs an die Standardausgabe, alles andere kommt
über die Fehlerausgabe. Damit kann ich die Ausgabe von fuser sehr bequem in
Scripts weiterverarbeiten:

    for p in $(fuser -m /); do
        lsof -p $p
    done

Will ich die Ausgabe allerdings in einem Pager betrachten, oder
dokumentieren, so schreibe ich:

    fuser -m / 2>&1 | less

Neben den Prozessen, die auf bestimmte Dateien zugreifen, bin ich manchmal
an allen Prozessen interessiert, die irgendeine Datei in einem Dateisystem
geöffnet haben. Dafür verwende ich die Option `--mount` (`-m`).
Das ist auch der einzige Weg, wie ich mit fuser Prozesse finden kann, die
bereits im Dateisystem gelöschte Dateien noch offen halten. Welche Prozesse
das konkret sind, kann ich zwar damit noch nicht sagen, aber das kann ich
zum Beispiel ermitteln, wenn ich die mit fuser ermittelten Prozesse mit lsof
näher betrachte.

Außer bei Dateien in Dateisystemen kann ich mit fuser auch die Prozesse
ermitteln, die bestimmte Sockets geöffnet haben. Dazu wähle ich den
entsprechenden Namensraum mit der Option `--namespace SPACE`
(`-n SPACE`) aus. Fuser kennt die folgenden Namensräume:

*file*
: ist der Standardnamensraum, der nicht extra angegeben werden muss.

*tcp*
: steht für TCP-Sockets

*udp*
: steht für UDP-Sockets

Sockets werden nach dem folgenden Schema angegeben:

    [local port][,[remote host][,[remote port]]][/namespace]

Den Namensraum kann ich angeben, wenn die Angabe eindeutig ist und ich
diesen nicht explizit mit `--namespace` angeben will.
Die Komma sind wichtig. So zeigt `fuser ssh/tcp` alle Prozesse, die mit
dem lokalen Port 22 arbein, währen `fuser ,,ssh/tcp` alle Prozesse mit
abgehender SSH-Verbindung an.

Mit der Option `-4` beziehungsweise `-6` kann ich die Ausgabe auf
die entsprechende Version des Internetprotokolls eingrenzen.

Eine Option, die ich eher selten anwende ist `--kill` (`-k`), mit
der fuser ein Signal (ohne weitere Angaben: `SIGKILL`) an die
ermittelten Prozesse sendet. Das Signal kann ich mit einem vorangestellten
Bindestrich (`-`) angeben, eine Liste der Signale bekomme ich mit
`--list-signals` (`-l`). Zum Beispiel könnte ich mit

    fuser -k -HUP 22/tcp

alle SSH-Anmeldungen an diesem Rechner beenden. War ich selbst via SSH
angemeldet, dann habe ich mich damit selbst hinausgeworfen. Oder, falls ich
ein Dateisystem aushängen will, beende ich mit

    fuser -k -m /media/cdrom

alle Prozesse, die auf die eingehängte CD-ROM zugreifen. Falls aber unter
/media/cdrom kein Dateisystem eingehängt war, werden alle Prozesse, die das
nächsthöhere Dateisystem (meist /) verwenden, beendet. Das kommt einem
Ausschalten des Rechners schon sehr nahe. Darum gibt es, quasi als
Sicherheitsgurt für solche Fälle, die Option `--ismountpoint`
(`-M`), mit der alle Aktionen nur dann ausgeführt werden, wenn der
angegebene Dateiname ein Mountpoint ist. Außerdem kann ich mit der Option
`-w` das Senden des Signals auf Prozesse einschränken, die eine Datei
zum Schreiben geöffnet haben. Das ist dann interessant, wenn ich das Datei
von read-write auf read-only umhängen will.

## lsof {#sec-lokal-werkzeuge-lsof}

Ein Werkzeug, dass in meinem Werkzeugkasten für die lokale Fehlersuche nicht
fehlen darf, ist lsof. Dieses Programm zeigt Informationen zu Dateien, die
von laufenden Prozessen geöffnet sind, an.

Ich habe dieses Programm erfolgreich beim Untersuchen von Mount-Problemen
eingesetzt.
Auch beim Aufspüren und Untersuchen von Sicherheitsproblemen leistet es
wertvolle Dienste.

Außer für Linux gibt es dieses Programm auch für andere UNIX-Derivate, bei
denen einige Optionen eine andere Bedeutung haben. Aus diesem Grund und weil
ich hier nicht alle Optionen erläutern werde, ist ein Blick in die
entsprechende Handbuchseite unumgänglich.

Offene Dateien, die lsof auflistet können

*   reguläre Dateien,

*   Verzeichnisse,

*   block- oder zeichenorientierte Spezialdateien,

*   Verweise auf ausführbaren Code,

*   Bibliotheken,

*   UNIX- oder Netzwerksockets sein.

In einigen Aspekten überschneidet sich die Funktionialität von lsof mit der
von netstat, welches ich weiter hinten im Abschnitt zu
[netstat](#sec-lokal-werkzeuge-netstat) beschreibe.
Meist entscheide ich je nach vorliegendem Problem, zu welchem
der Programme ich greife.

Es ist möglich, von lsof statt einer einmaligen Ausgabe, automatisch in
bestimmten Abständen neue Schnappschüsse der angeforderten Informationen zu
erhalten und die Ausgabe dazu so umzuformen, dass sie gut von einem Skript
oder sonstigem Programm überwacht werden kann.

Rufe ich lsof ohne Optionen und Argumente auf, bekomme ich eine Liste aller
Dateien, die alle laufenden Prozesse im Moment geöffnet haben. Bin ich nur
an wenigen Dateien interessiert, gebe ich diese als Argumente auf der
Kommandozeile an. Bin ich nur an bestimmten Aspekten oder an Dateien, die
ich zwar selbst nicht genau kenne, aber deren Eigenschaften, so
spezifiziere ich das mit Optionen. Einige dieser Optionen will ich hier
vorstellen.
  
Selektiere ich mit einer Option eine definierte Menge von
Dateien, dann werden nur die Dateien, die dieser Selektion genögen,
angezeigt. Gebe ich mehrere Selektoren an, dann werden alle Dateien
angezeigt, die irgendeinem dieser Selektoren entsprechen. Das heißt, die
Menge der angezeigten Dateien entspricht der ODER-Verknüpfung der einzelnen
Selektoren. Dazu gibt es folgende Ausnahme: wenn ich mit einer Option
bestimmte Dateien deselektiere (zum Beispiel durch vorangestelltes `^`
bei Auswahllisten), dann werden diese Dateien auch nicht angezeigt, wenn sie
nach einem anderen Selektor drann wären. Außerdem kann ich die Verknüpfung
der Selektionskriterien mit der Option `-a` von ODER auf UND umstellen.
Gebe ich mehrmals die gleiche Option mit verschiedenen Selektoren an, so
werden diese vor der ODER- beziehungsweise UND-Verknüpfung zu einem Selektor
zusammengefasst.

Wenn ich zum Beispiel nur an allen Internetsockets interessiert bin, die von
Prozessen mit UID xyz geöffnet sind, dann schreibe ich:

    lsof -a -i -u xyz

  
Nun zu den Optionen.

Mit Option `-c name` selektiere ich Prozesse, deren Name mit `name`
beginnt. Fängt `name` selbst mit `^` an, dann werden genau diese
Prozesse ignoriert. Beginnt und endet `name` mit einem Schrägstrich
(`/`), dann wird er als regulärer Ausdruck interpretiert.

Mit der Option `+d s` bekomme ich alle geöffneten Dateien direkt im
Verzeichnis `s`. Demgegenüber liefert `+D s` auch die Dateien und
Verzeichnisse in den Unterverzeichnissen von `s`, die von Prozessen
geöffnet sind. Beide Optionen kann ich mit `-x` kombinieren, damit lsof
symbolischen Links folgen und Mountpoints überqueren soll, was es ansonsten
nicht machen würde.

Die Option `-d s` erwartet eine Liste von Dateideskriptoren (diese
stehen in der Ausgabe in Spalte FD), die ich einschließen, oder mit `^`
ausschließen kann. Möchte ich zwar das Arbeitsverzeichnis, aber nicht die
Standardeingabe, -ausgabe und -fehlerausgabe von Prozessen wissen, dann
drücke ich das so aus:

    lsof -d cwd,^0,^1,^2


Mit der Option `-i [m]` bekomme ich Internetsockets und zwar speziell
für TCP oder UDP angezeigt. Optional kann ich diese mit dem Muster `m`
genauer spezifizieren. Dazu gebe ich `m` in der folgenden Form
`[46][protocol][@hostname|hostaddr][:service|port]` an. Hierbei steht

*4*
: für die Beschränkung auf IPv4

*6*
: für die Beschränkung auf IPv6

*protocol*
: für den Protokollnamen TCP oder UDP

*hostname*
: für einen Internet-Hostnamen oder alternativ

*hostaddr*
: für eine numerische Adresse

*service*
: für einen Servicenamen aus /etc/services oder alternativ

*port*
: für die Portnummer

Demgegenüber kann ich mit `-U` UNIX-Domain-Sockets auswählen.

Die Option `-n` unterdrückt die Umwandlung von Netzadressen in Namen,
`-P` die Umwandlung von Portnummern in Servicenamen und schließlich
`-l` die Umwandlung von UID in Benutzernamen. Diese Optionen verwende
ich, wenn ich mehr Klarheit haben will, oder wenn diese Umwandlung
ihrerseits die Ausführung von lsof verzögert, weil DNS- oder NIS-Anfragen
für die Auflösung notwendig sind.

Mit der Option `-u s` lassen sich die Prozesse nach UID oder
Benutzernamen auswählen, während ich mit `-p s` die Prozesse direkt
nach PID auswählen kann.

Starte ich lsof mit Otion `-r [t]`, so liefert es die Informationen
wiederholt in dem mit `t` spezifizierten Zeitabstand (ohne Angabe 15
Sekunden). Diese Option kann ich mit `-F f` kombinieren um die Ausgabe
für die einfachere Verarbeitung in einem Skript zu modifizieren.

## netstat {#sec-lokal-werkzeuge-netstat}

Ein Werkzeug, das sowohl bei der lokalen, als auch bei der Fehlersuche im
Netzwerk behilflich sein kann, ist netstat. Auf den Aspekt
Netzwerkfehlersuche gehe ich im Abschnitt über den
[Einsatz von netstat bei Netzwerkfehlern](#sec-netz-werkzeuge-netstat)
näher ein. Hier konzentriere ich mich auf die Fehlersuche bei lokalen
Problemen.

Dafür verwende ich vor allem die Optionen `--protocol=unix`
(alternativ: `-A unix`) oder `--unix` (`-x`) um mir die
UNIX-Sockets ausgeben zu lassen.
Bin ich an den Prozessen interessiert, die die Netzwerksockets verwenden,
kann ich diese stattdessen mit `--inet`, `--ipx`, `--tcp`,
... selektieren. Das ist ausführlicher im Abschnitt zu
[netstat bei Netzwerkzeugen](#sec-netz-werkzeuge-netstat) beschrieben.

Mit `--program` (`-p`) erhalte ich die PID und den Namen des
Prozesses, der den Socket benutzt. Dafür benötige ich Superuser-Privilegien.
Mit dieser PID kann ich dann zum Beispiel den Prozess mit strace näher
betrachten.

Normalerweise zeigt netstat nur aktive, das heißt verbundene Sockets an. Mit
der Option `--listening` (`-l`) kann ich dagegen nur die Sockets
ausgeben lassen, die auf eine Verbindung warten oder mit `--all`
(`-a`) alle.

Mehr Informationen kann ich bekommen, wenn ich zusätzlich die Optionen
`--verbose` (`-v`) oder `--extend` (`-e`) angebe.

Die Ausgabe von netstat kommt als Tabelle, deren Spalten die folgende
Bedeutung haben:

**RefCnt**
: Zeigt die Anzahl der Prozesse, die sich mit dem Socket verbunden haben.

**Flags**
: geben zusätzliche Informationen zum Zustand des Sockets aus:

  **ACC**
  : - der Socket wartet auf eine Verbindung

  **W**
  : - der Socket wartet auf Daten

  **N**
  : - der Socket hat im Moment nicht genug Platz zum Schreiben

**Typ**
: kann stehen für

  **DGRAM**
  : für verbindungslose Sockets

  **STREAM**
  : für verbundene Sockets

  **RAW**
  : für rohe ungefilterte Sockets %XXX FIXME

  **RDM**
  : für zuverlässig ausgelieferte Nachrichten (Reliable
          Delivered Messages)

  **SEQPACKETS**
  : für nacheinander folgende Pakete %XXX FIXME

  **PACKET**
  : für rohe Interface-Sockets %XXX FIXME

**State**
: kann für einen der folgenden Zustände des Sockets stehen:

  **Free**
  : - nicht allozierte Sockets %XXX FIXME

  **Listening**
  : - nicht verbundene Sockets

  **Connecting, Connected, Disconnected**
  : - die Phasen einer Socketverbindung

  **(empty)**
  : für unverbundene Sockets %XXX FIXME

**PID**
: enthält die Prozess-ID und den Namen des Prozesses

**Path**
: zeigt den Pfad zum Socket vom Prozess aus an, relativ zum
Arbeitsverzeichnis des Prozesses

## iproute {#sec-lokal-werkzeuge-iproute}

Ein Werkzeug, dass in keinem Werkzeugkasten für die lokale Fehlersuche fehlen
Iproute ist ein Softwarepaket, dass ich am häufigsten bei Netzwerkproblemen
einsetze. Zwei Programme daraus, ip und ss, nutze ich auch bei lokalen
Problemen, daher stelle ich sie bereits hier vor. Diese beiden Programme
überschneiden sich in der Funktionalität der Programme mit ifconfig, route,
netstat und arp.
  
Im Kapitel über [Werkzeuge für Netzwerkprobleme](#cha-netz-werkzeuge) gehe
ich noch etwas ausführlicher auf iproute ein. 

### ip

Das Programm `ip` funktioniert nach dem Schema

    ip [optionen] objekt befehl

Die komplette Syntax ist in der Handbuchseite beschrieben. Ich bin bei der
lokalen Fehlersuche vor allem an folgenden Objekten interessiert:

*link*
: Schnittstellenparameter

*addr*
: IP-Adressen

*neigh*
: ARP- und NDISC-Caches

*route*
: IP-Routingtabellen

Zu allen Objekten kann ich mit

    ip objekt help

eine Kurzübersicht der möglichen Befehle und Optionen bekommen.

Bei der lokalen Fehlersuche verwende ich am häufigsten den Befehl show, um
mir den momentanen Zustand anzusehen. Die anderen Objekte und Befehle
benötige ich eher selten zur Fehlersuche.

### ss

Das Programm `ss` (show sockets) zeigt Informationen über Sockets an.
Dabei kann ich auswählen, ob ich mit

*-t*
: TCP-Sockets, mit

*-u*
: UDP-Sockets, oder mit

*-x*
: UNIX-Sockets

betrachten will.

Die Ausgabe kann ich mit folgenden Optionen beeinflussen:

*-n*
: schaltet die Namensauflösung ab.

*-r*
: schaltet die Namensauflösung ein.

*-l*
: zeigt Listening Sockets anstelle von Connected Sockets.

*-a*
: zeigt sowohl Listening als auch Connected Sockets.

*-p*
: zeigt die Prozesse, die einen Socket verwenden.

Auch hier helfen die Handbuchseiten weiter.

## GDB der GNU Debugger {#sec-lokal-werkzeuge-gdb}

GDB ist ein sehr mächtiges Werkzeug, das eher in extrem schwierigen Fällen
zum Einsatz kommt. Vorzugsweise, wenn ich nachträglich die Ursache eines
Programmabsturzes ermitteln will oder wenn ich einen Programmfehler vermute
und finden will.

Um mit dem Debugger zu arbeiten benötige ich Zugriff auf die Quellen, aus
denen das betreffende Programm übersetzt wurde [^gdb-machine-code].
Außerdem brauche ich die Symboltabellen des Programms damit der Debugger die
Maschinenbefehle des Binärprogramms den Quellcodezeilen zuordnen kann. Diese
bekomme ich, wenn zum Beispiel beim Übersetzen des Programms mit dem
Compiler gcc die Option `-g` angegeben wurde. Bei vielen Softwarpaketen
kann ich die Symboltabellen über das entsprechende Paket mit der Option
`-dbg` (zum Beispiel `avahi-dbg` für `avahi`) installieren.

[^gdb-machine-code]: Zwar ist es auch möglich, direkt die Maschinenbefehle
                     zu verfolgen, aber das liegt definitiv jenseits des
		     Horizonts dieses Buches.

Um einen Prozess postmortal zu analysieren, muss ich das System anweisen ein
sogenanntes Corefile zu schreiben, das den Zustand des Prozesses beim
Programmabsturz enthält. Dazu kann ich in der Bash mit dem Befehl
`ulimit -c size` die maximale Größe des Corefiles festlegen, die das
Betriebssystem schreibt. Diese muss ich hoch genug wählen, damit das
Corefile für den gewünschten Prozess reicht.

Ich kann den GNU Debugger auf verschiedene Arten starten:

*gdb options program core*
: So starte ich, wenn ich einen Prozess postmortal analysieren will
(mit `core`) oder, wenn ich ein Programm nur beim Ablauf verfolgen will
(ohne `core`). Dabei ist `program` der Name der Programmdatei und
`core` der Name des Corefiles.

*gdb options --args program arguments*
: Hier gebe ich dem
Programm, dass ich beobachten will gleich die Kommandozeilenargumente
beim Aufrauf des GDB mit.

*gdbtui options*
: Das startet den GDB mit einer
Textbenutzeroberfläche, bei der im oberen Teil der aktuelle Quelltext
angezeigt wird und im unteren Teil die Befehle und Ausgaben des GDB.

Von den Optionen, die GDB beim Aufruf mitgegeben werden können, sind die
folgenden für die Fehlersuche relevant, weitere können der Handbuchseite,
der GDB-Texinfo-Datei oder `gdb -help` entnommen werden:

*-c file | -core file*
: Damit gebe ich das Corefile bei den Optionen
an und brauche es nicht mehr nach dem Programmnamen anzugeben.

*-e file | -exec file*
: Gibt das ausführbare Programm an.

*-s file | -symbols file*
: Gibt die Datei mit den Symboltabellen an.
Die Optionen `-s` und `-e` können auch zu `-se`
zusammengefasst werden, wenn die Symboltabellen noch in der
Binärprogrammdatei enthalten sind.

*-help*
: Listed alle Optionen mit einer kurzen Erläuterung auf.

Nachdem ich GDB gestartet habe, steuere ich den Ablauf der Sitzung mit
Textbefehlen. Alle diese Befehle können soweit abgekürzt werden, wie sie
noch eindeutig sind.
Die wichtigsten dieser Befehle für die Fehlersuche sind:

*break function | break file:function*
: So ziemlich als erstes rufe
ich in einer Debuggingsitzung `break main` auf, damit der Debugger
an dieser Funktion anhält und ich anschließend das Programm in Ruhe
analysieren kann. Vor einer Funktion kann ich, durch `:` getrennt
die Datei angeben, falls der Debugger momentan eine andere geladen hat.

*run | run arglist*
: Damit starte ich das Programm im Debugger.
Optional kann ich dem Prozess mit `arglist` einige
Kommandozeilenargumente mitgeben.

*bt*
: Dieser Befehl zeigt den Programmstack an. Bei einer postmortalen
Analyse eines Prozesses rufe ich diesen Befehl als erstes auf, um
herauszubekommen, wo genau das Programm abgestürzt ist.

*print expr*
: Mit `print` lasse ich mir die Werte in den
Variablen und verschiedene andere Datein ausgeben. Dabei kann
`expr` ein komplexer C-Ausdruck sein.

*c*
: Mit `c` (continue) läuft das Programm weiter bis zum
nächsten Haltepunkt oder bis zum Programmende.

*next*
: Dieser Befehl arbeitet die nächste Zeile im Quelltext ab.
Dabei werden Funktionsaufrufe ausgeführt und übersprungen.

*step*
: Auch dieser Befehl arbeitet die nächste Zeile im Quelltext ab,
der Debugger folgt hier allerdings Funktionsaufrufen in das Innere der
Funktion.

*list | list function | list file:function*
: Zeigt die aktuelle
Programmumgebung beziehungsweise die angegebene Funktion im Quelltext.

*help befehl*
: Gibt die Hilfe zu dem angegebenen Befehl aus.

*quit*
: Beendet die Debuggersitzung.

GDB ist ein sehr mächtiges Werkzeug für die Fehlersuche und auch sehr
komplex in der Anwendung. Da die Bedienung nicht einfach ist und es auch
einiger Vorkehrungen für den erfolgreichen Einsatz bedarf, setze ich ihn
eher selten ein, quasi als Ultima Ratio. Trotzdem ist es sinnvoll, sich
gelegentlich hinzusetzen und testweise das eine oder andere Programm im
Debugger zu beobachten und zu analysieren, damit es im Ernstfall, wenn man
darauf angewiesen ist, einfacher von der Hand geht.

## sysstat {#sec-lokal-werkzeuge-sysstat}

Sysstat ist ein Werkzeug zur Einschätzung der Systemperformance.

Üblicherweise wird via cron aller 10 Minuten ein Skript gespeichert, das die
Systemstatistiken sichert. Diese Statistiken können dann mit verschiedenen
Auswertewerkzeugen ausgelesen werden.

Alternativ können diese Werkzeuge auch selbst periodisch die
Performancedaten sammeln und als aktuelle Schnappschüsse ausgeben.

Zur Auswertung mit sysstat stehen die folgenden Werkzeuge zur Verfügung:

*cifsiostat*
: liefert CIFS Statistiken

*iostat*
: liefert CPU- und I/O-Statistiken für Geräte und Partitionen

*mpstat*
: liefert (multi-)prozessorbezogene Statistiken

*nfsiostat*
: liefert NFS-bezogene I/O-Statistiken

*pidstat*
: liefert Statistiken über Linux-Tasks (-Prozesse)

*sar, sadf*
: Sar sammelt, berichtet und sichert Informationen zu
  Systemaktivitäten, sadf gibt die von sar gesammelten Daten in
  verschiedenen Formaten aus.

Die Auswertung der Statistikdaten mit sar wurde bereits in
[Loukides1996](#bib-loukides1996) beschrieben. Da sich die Software seitdem
weiterentwickelt hat, ist ein Blick in die Handbuchseiten unerlässlich.

Für die grafische Auswertung gibt es verschiedene Programme. Ein
Programm, sargraph, wird als Beispiel mit sysstat verteilt. Dieses wertet
die XML-Ausgabe von sadf auf und übergibt sie an gnuplot zur Darstellung.

## acct {#sec-lokal-werkzeuge-acct}

Abrechnungsprogramme spielen eine wichtige Rolle im Gesamtbild der
Performanceoptimierung. Sie liefern einen einfachen Weg herauszufinden, was
ein Rechner macht. Welche Anwendungen laufen, wieviel Systemzeit verbrauchen
diese Programme, wie stark belasten sie das System, und so weiter. Wenn man
die Programme und ihr Verhalten im Großen und Ganzen kennt, kann man sich
an die Strategie machen, um die Performance zu optimieren. Das Programmpaket
acct liefert diese Abrechnungsdaten.

Natürlich belastet das Führen der Statistiken das System zusätzlich. Und
zusätzlichen Plattenplatz benötigen die Statistiken auch. Andererseits: wenn
das System schon deutlich auf das Einschalten der Statistikerfassung
reagiert, arbeitet es bereits in einem Bereich nahe der Belastungsgrenze und
eine Analyse der Systemperformance und entsprechende Maßnahmen sind schon
längst fällig.

Ist das Paket acct installiert, so wird das Accounting meist automatisch
beim Systemstart via accton eingeschaltet. Will man es deaktivieren, reicht
es meist nicht, das über das Startscript auszuschalten, da durch cron in
regelmäßigen Abständen die Protokolle komprimiert werden und dazu das
Accounting ab und wieder angeschaltet wird. Um das Accounting zu
deaktivieren ändert man bei Debian-Systemen in /etc/default/acct die
Variable `ACCT_ENABLE` auf 0.

Die Abrechnugsdaten werden mit dem Programm sa ausgewertet. Dieses Programm
gibt eine Tabelle mit einer Zeile für jedes Programm, mit der Anzahl der
Aufrufe des Programms in der ersten Spalte und die folgenden Bezeichnungen
in den anderen Spalten enthält:

*cpu*
: die Summe von von CPU-System- und -Userzeit in CPU-Minuten

*re*
: die ``wirkliche'' Laufzeit des Programms

*k*
: der durchschnittliche Speicherverbrauch in KByte. Der
  Durchschnitt basiert auf der CPU-Zeit des Programms.

*avio*
: die durchschnittliche Anzahl von I/O-Operationen pro Programmaufruf

*tio*
: die Gesamtzahl der I/O-Operationen

*k*sec*
: das Integral über den Speicher und die CPU-Zeit

*s*
: die Systemzeit

*u*
: die Benutzerzeit

Ganz rechts, ohne Bezeichnung steht der Programmname.  
Ist dieser mit einem Asterisk ('*') gekennzeichnet, ist das Programm als
Daemon gelaufen. Das heißt, es hat `fork()` aufgerufen, aber nicht
`exec()`. Daemon-Prozesse sammeln durch ihre lange Laufzeit auch sehr
viel CPU-Zeit an und verfälschen damit die Werte für den durchschnittlichen
Speicherverbrauch.

Die Tabelle ist nach der CPU-Zeit absteigend sortiert.

Programme, die nur einmalig gelaufen sind, werden in der Zeile
`***other*` zusammengefasst.

Mit den folgenden Optionen kann ich die Ausgabe von sa modifizieren, die
Handbuchseite kennt noch mehr davon:

*-a | --list-all-names*
: Zeigt alle Programme (fasst keine Programme unter
  `***other*` zusammen).

*-b | --sort-sys-user-div-calls*
: Sortiert die Aufrufe nach der
  CPU-Zeit geteilt durch die Anzahl der Aufrufe.

*-d | --sort-avio*
: Sortiert nach der durchschnittlichen Anzahl der
  I/O-Operationen.

*-D | --sort-tio*
: Sortiert nach der Gesamtzahl der I/O-Operationen.

*-i | --dont-read-summary-file*
: Ignoriert die Auswertungsdatei. Mit
  dieser Option zeigt sa die Prozesse seit dem letzten Aufruf von 
  `sa -s`.

*-k | --sort-cpu-avmem*
: Sortiert nach dem durchschnittlichen
  Speicherverbrauch. Dieser Report identifiziert die größten
  Speichernutzer.

*-n | --sort-num-calls*
: Sortiert nach der Anzahl der Aufrufe,
  identifiziert die am häufigsten aufgerufenen Programme.

*-r | --reverse-sort*
: Dreht die Sortierreihenfolge um.

*-s | --merge*
: Fasst die aktuellen Accountingdaten in der
  Auswertungsdatei zusammen.

*-t | --print-ratio*
: Zeigt das Verhältnis von Laufzeit zu CPU-Zeit,
  identifiziert Programme mit sehr viel Leerlauf.

## bonnie++ {#sec-lokal-werkzeuge-bonnie}

Bei jeglicher Art von Performance Tuning ist es essentiell, eine
Bestandsaufnahme vor den Tuning-Maßnahmen und danach zu machen, um sich von
der Wirkung des Tunings zu überzeugen.
Bonnie++ ist ein Programm, mit dem ich die Performance der Lese- und
Schreiboperationen im Dateisystem in Zahlen ausdrücken und damit dann
vergleichen kann.

Dabei gibt das Programm für jeden Test, den es durchführt, zwei Kennzahlen
aus: die geschaffte Arbeit (je mehr, um so besser) und die dafür benötigte
CPU-Zeit (je weniger, umso besser).

Die Tests teilen sich grob in zwei Abschnitte, die man gegebenenfalls auch
überspringen kann. In einem Abschnitt testet bonnie++ den I/O-Durchsatz mit
relativ großen Dateien, wie er ähnlich auch bei Datenbankanwendungen
vorkommt. Im anderen Abschnitt geht es um das Erzeugen, Lesen und Löschen
vieler relativ kleiner Dateien, wie es ähnlich auf Proxy-, Mail- und
News-Servern vorkommt.

In den meisten Fällen ist man eher daran interessiert, das I/O-Verhalten bei
einzelnen Dateisystemen zu beobachten. Bei bestimmten Problemen möchte man
jedoch den Einfluss von gleichzeitigen Dateizugriffen bewerten. Zu diesem
Zweck ist es möglich, mehrere bonnie++ Prozesse synchron zu starten.

Die Ausgabe von bonnie++ kommt, wie schon beim Vorgängerprogramm bonnie als
achtzigspaltiger Text. Zusätzlich gibt bonnie++ die Werte auch noch als
kommaseparierte Werte (CSV) aus, die einfacher weiterverarbeitet werden
können und mehr als 80 Zeichen pro Zeile einnehmen können. Für diese
CSV-Daten gibt es zwei Programme (`bon_csv2html`, `bon_csv2txt`),
die die Daten für die HTML-Ausgabe beziehungsweise das bekannte Textformat
aufbereiten. In deren Handbuchseiten sind die Felder der CSV-Daten
beschrieben.

Eine Warnung will ich noch vorwegschicken, bevor ich mich den Optionen
zu wende, die, wie üblich, in den Handbuchseiten ausführlicher beschrieben
werden.
**Bonnie++ sollte niemals auf aktiven Produktionsmaschinen laufen, da die
Performance durch die Tests sehr stark beeinträchtigt wird.**

### Optionen

*-d dir*
: Das Verzeichnis, in dem die Testdateien angelegt werden.
  Ohne Angabe dieser Option werden die Testdateien im aktuellen
  Verzeichnis angelegt.

*-s size*
: Die Größe der Dateien für die I/O-Performance-Tests. Mit
  einer Größe von 0 wird dieser Test übersprungen.

*-n number*
: Die Anzahl der Dateien für den Dateierzeugungstest. Die
  Anzahl wird als Vielfache von 1024 angegeben. Ist die Anzahl 0, wird
  dieser Test übersprungen. Per Default werden leere Dateien angelegt. Es
  ist möglich, die maximale und minimale Größe der Dateien und die Anzahl
  der Verzeichnisse durch Doppelpunkt getrennt gemeinsam mit der Anzahl
  anzugeben. Details stehen in den Handbuchseiten.

*-x number*
: Anzahl der Testläufe. Damit ist es möglich,
  hintereinander weg mehrere Tests zu machen, die Ergebnisse kommen
  kontinuierlich als CSV-Daten.

*-u user*
: Der Benutzer, unter dem der bonnie++ Prozess laufen soll.
  Bonnie++ kann als normaler Nutzer gestartet werden. Startet man es als
  root, gibt man mit dieser Option besser einen anderen Benutzer vor, um
  Fehler am Dateisystem zu vermeiden.

*-q*
: Mit dieser Option gibt bonnie++ nur die CSV-Daten an STDOUT aus.
  Dateien angelegt.

*-f | -f size*
: Fast Mode Control, überspringt den zeichenweisen
  I/O-Test, wenn kein Parameter ansonsten gibt es die Testgröße für
  zeichenweisen I/O-Test vor (default 20M)

*-b*
: Keine Pufferung der Schreiboperationen, das heisst es wird
  `fsync()` nach jedem Schreiben aufgerufen.

*-q*
: Quiet Mode. Es wird ein Teil der Ausgabe unterdrückt, an STDOUT
  werden nur die CSV-Daten ausgegeben, alles andere an STDERR. Damit ist
  es einfacher, die Ausgabe weiter zu verarbeiten.

*-p number*
: Die Anzahl der der Prozesse, für die Semaphore
  reseerviert werden sollen. Alle Prozesse, die Semaphore mit Option
  `-ys` verwenden, starten synchron.

*-y s*
: Durch Semaphor synchronisiert starten

*-y p*
: Mit Prompt synchronisieren. Bonnie++ startet erst, wenn
  `<RETURN>` eingegeben wurde.

*-D*
: Direct-I/O (`O_DIRECT`) für Massen-I/O-Tests verwenden.
  \item[-z seed] Die Startzahl für den Zufallsgenerator angeben, um den
  gleichen Test zu wiederholen.

*-Z file*
: Zufallsdaten aus der angegebenen Datei verwenden.

### Synchrone Tests

Um mehrere Prozesse mit bonnie++ synchron zu starten, kann ich wie folgt
vorgehen:

    $ bonnie++ -p3
    $ bonnie++ [weitere Optionen] -ys > out1 &
    $ bonnie++ [weitere Optionen] -ys > out2 &
    $ bonnie++ [weitere Optionen] -ys > out3 &

### Signale

Bonnie++ kann mitunter recht lange laufen, vor allem wenn es mit Option
`-x`  seine Tests wiederholt.

Mit SIGINT kann man die Ausführung abbrechen, bonnie++ räumt dann wieder
auf, das heißt, es entfernt die temporären Dateien und Verzeichnisse. Das
kann auch etwas dauern. Durch wiederholtes Senden von SIGINT bricht es auch
das Aufräumen ab.

SIGHUP wird ignoriert, das heißt, wenn es im Hintergrund läuft, bricht es
auch nicht nach Abmelden vom Terminal ab.

## hdparm {#sec-lokal-werkzeuge-hdparm}

Mit hdparm kann ich von der Kommandozeile aus Einfluß nehmen auf die
Schnittstelle zur Festplatte des Rechners. Ich verwende das Programm zum
Feintuning der Festplattenzugriffe aber auch zum Verifizieren und Beheben
von Plattenfehlern. Es arbeitet mit der Kernelschnittstelle des SATA-, PATA-
und SAS-Subsystems zusammen. Auch bei manchen USB-Festplatten kann ich
Parameter mit hdparm verändern. Für einige der Optionen benötige ich eine
aktuelle Kernelversion.

Allgemein sieht der Aufruf von hdparm wie folgt aus:

    hdparm [optionen] [geraet ..]

Es gibt Optionen, mit denen ich Parameter sowohl abfragen als auch setzen
kann (get/set). Bei diesen Optionen gilt, dass sie ohne weiteres Argument
den Parameter abfragen und mit zusätzlichem Argument den Wert entsprechend
setzen.

Rufe ich hdparm ganz ohne Parameter auf, verhält es sich,
als hätte ich die Optionen `-acdgkmur` angegeben.

In der Datei `/etc/hdparm.conf` kann ich die Default-Konfiguration für
hdparm systemweit hinterlegen.

Nachfolgend beschreibe ich die, aus meiner Sicht, wichtigsten Optionen.
Weitere Informationen gibt es, wie fast immer, in den Handbuchseiten.

*-a*
: (get/set) Anzahl der Sektoren für das Vorauslesen (read-ahead)
  im Dateisystem. Damit verbessert sich die Performance beim sequentiellen
  Lesen großer Dateien. Es gibt noch eine, davon separate,
  Read-Ahead-Funktion der Festplatte, diese Funktion unterstützt.

*-A*
: (get/set) Ein- oder Ausschalten der Vorauslesefunktion der Festplatte.
  Mit `-A0` wird es ausgeschaltet, mit `-A1`  eingeschaltet.

*-B*
: (get/set) Einstellen Advanced Power Management (APM)
  Eigenschaften der Platte, soweit diese das unterstützt. Gültig sind
  Werte von 1 (meiste Energieeinsparung) bis 254 (höchste
  I/O-Performance), mit dem Wert 255 wird es ganz abgeschaltet. Werte von
  1-127 erlauben einen Spin-Down der Festplatte, Werte von 128-254
  erlauben das nicht.

*-c*
: (get/set) 32-Bit-Support für (E)IDE ein- oder ausschalten.
  Mit 0 wird dieser Ausgeschaltet, 1 schaltet ihn ein und 3 schaltet den
  32-bit-Support mit speziellem Sync.

  Es geht hierbei um den Transfer via PCI oder VLB zum Hostadapter. Das
  Kabel zur Festplatte hat immer 16 Bit.

*--fibmap dateiname*
: Gibt eien Liste von Blockextents
  (Sektorbereichen), den die Datei auf der Platte belegt.

  Damit kann ich mir die Fragmentierung einer Datei auf der Platte
  ansehen, oder die Blöcke für Fehlertests bestimmen.

  Wenn diese Option verwendet wird, muss sie die einzige sein.

*-g*
: Zeigt die Laufwerksgeometrie (Zylinder, Köpfe, Sektoren), die
  Größe des Gerätes in Sektoren und den Startoffset von Beginn der Platte.

*-i*
: Zeigt Identifizierungsinformationen, die die Kerneltreiber
  während des Systemstarts und der Konfiguration gesammelt haben.

*-I*
: Zeigt die Identifizierungsinformationen, die das Laufwerk liefert.

*-m*
: (get/set) Die Anzahl der Sektoren für multiple Sektor I/O. Mit
  dem Wert 0 wird das abgeschaltet. Die meisten IDE-Festplatten erlauben
  die Übertragung von mehreren Sektoren pro Interrupt. Damit läßt sich der
  System Overhead für Disk I/O um typisch 30 bis 50 Prozent reduzieren. Es
  kann allerdings in seltenen Fällen zu massiven Dateisystemfehlern
  führen.

*--read-sector sektornummer*
: Liest den angegebenen Sektor und
  schreibt den Inhalt in Hex-Darstellung zum Standardausgang. Die
  Sektornummer muss als Dezimalzahl angegeben werden. Hdparm führt einen
  Low-Level-Read für diesen Sektor  aus. Damit kann diese Funktion als
  definitiver Test, ob ein Sektor schlecht ist, genommen werden. Um den
  Sektor durch die Platte ersetzen zu lassen, kann man die Option
  `--write-sector` verwenden.

*-t*
: Nimmt die Zeit von Lesezugriffen für Benchmarks und
  Vergleichsmessungen. Um brauchbare Werte zu erhalten, muss man diese
  Funktion mindestens zwei mal bei einem ansonsten inaktiven System (keine
  anderen aktiven Prozesse) und genügend freiem Hauptspeicher ausführen. 
  Diese Funktion zeigt, wie schnell Daten ohne den Overhead des
  Dateisystems gelesen werden können.

*-T*
: Nimmt die Zeit von Cache-Read-Zugriffen. Auch diese Funktion
  sollte mindestens zwei mal bei ansonsten inaktivem System wiederholt
  werden. Das zeigt den Durchsatz von Prozessor, Cache und RAM.

*--write-sector sektornummer*
: Schreibt Nullen in den Sektor. **Sehr gefährlich!** Irrt man
  sich in der Sektornummer, werden möglicherweise vitale Informationen des
  Dateisystems überschrieben. Die Sektornummer wird als Dezimalzahl
  angegeben.
  Diese Funktion kann zum Anstoßen der automatischen
  Reparatur des Sektors durch die Festplatte verwendet werden.
  Sinnvollerweise vergewissert man sich vorher mit der Option
  `--read-sector`, das man es wirklich mit einem defekten Sektor zu
  tun hat.

*-W*
: (get/set) Zeigt beziehungsweise modifiziert das Write Caching
  des IDE/SATA Laufwerks. 1 bedeutet, dass es eingeschaltet ist.

*-z*
: Zwingt den Kernel, die Partitionstabelle neu zu lesen.

In der Datei /etc/hdparm.conf kann die Default-Konfiguration für hdparm
hinterlegt werden. Diese Datei ist gut kommentiert, so dass ich mir weitere
Erläuterungen hier spare.

## Notizen

*   Wie installiere ich Software?

*   Was für eine Kernelschnittstelle nutzt strace?

*   Strace-Skript: Datum, Kommandozeile, Umgebung, Benutzer,
    Standardeingabe, Strace-Ausgabe

*   Diskussion: wann ltrace, wann strace

*   Was bedeutet aktive / inactive bei Memory? (vmstat)
