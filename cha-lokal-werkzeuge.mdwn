
## iproute {#sec-lokal-werkzeuge-iproute}

Ein Werkzeug, dass in keinem Werkzeugkasten für die lokale Fehlersuche fehlen
Iproute ist ein Softwarepaket, dass ich am häufigsten bei Netzwerkproblemen
einsetze. Zwei Programme daraus, ip und ss, nutze ich auch bei lokalen
Problemen, daher stelle ich sie bereits hier vor. Diese beiden Programme
überschneiden sich in der Funktionalität der Programme mit ifconfig, route,
netstat und arp.
  
Im Kapitel über [Werkzeuge für Netzwerkprobleme](#cha-netz-werkzeuge) gehe
ich noch etwas ausführlicher auf iproute ein. 

### ip

Das Programm `ip` funktioniert nach dem Schema

    ip [optionen] objekt befehl

Die komplette Syntax ist in der Handbuchseite beschrieben. Ich bin bei der
lokalen Fehlersuche vor allem an folgenden Objekten interessiert:

*link*
: Schnittstellenparameter

*addr*
: IP-Adressen

*neigh*
: ARP- und NDISC-Caches

*route*
: IP-Routingtabellen

Zu allen Objekten kann ich mit

    ip objekt help

eine Kurzübersicht der möglichen Befehle und Optionen bekommen.

Bei der lokalen Fehlersuche verwende ich am häufigsten den Befehl show, um
mir den momentanen Zustand anzusehen. Die anderen Objekte und Befehle
benötige ich eher selten zur Fehlersuche.

### ss

Das Programm `ss` (show sockets) zeigt Informationen über Sockets an.
Dabei kann ich auswählen, ob ich mit

*-t*
: TCP-Sockets, mit

*-u*
: UDP-Sockets, oder mit

*-x*
: UNIX-Sockets

betrachten will.

Die Ausgabe kann ich mit folgenden Optionen beeinflussen:

*-n*
: schaltet die Namensauflösung ab.

*-r*
: schaltet die Namensauflösung ein.

*-l*
: zeigt Listening Sockets anstelle von Connected Sockets.

*-a*
: zeigt sowohl Listening als auch Connected Sockets.

*-p*
: zeigt die Prozesse, die einen Socket verwenden.

Auch hier helfen die Handbuchseiten weiter.

## GDB der GNU Debugger {#sec-lokal-werkzeuge-gdb}

GDB ist ein sehr mächtiges Werkzeug, das eher in extrem schwierigen Fällen
zum Einsatz kommt. Vorzugsweise, wenn ich nachträglich die Ursache eines
Programmabsturzes ermitteln will oder wenn ich einen Programmfehler vermute
und finden will.

Um mit dem Debugger zu arbeiten benötige ich Zugriff auf die Quellen, aus
denen das betreffende Programm übersetzt wurde [^gdb-machine-code].
Außerdem brauche ich die Symboltabellen des Programms damit der Debugger die
Maschinenbefehle des Binärprogramms den Quellcodezeilen zuordnen kann. Diese
bekomme ich, wenn zum Beispiel beim Übersetzen des Programms mit dem
Compiler gcc die Option `-g` angegeben wurde. Bei vielen Softwarpaketen
kann ich die Symboltabellen über das entsprechende Paket mit der Option
`-dbg` (zum Beispiel `avahi-dbg` für `avahi`) installieren.

[^gdb-machine-code]: Zwar ist es auch möglich, direkt die Maschinenbefehle
                     zu verfolgen, aber das liegt definitiv jenseits des
		     Horizonts dieses Buches.

Um einen Prozess postmortal zu analysieren, muss ich das System anweisen ein
sogenanntes Corefile zu schreiben, das den Zustand des Prozesses beim
Programmabsturz enthält. Dazu kann ich in der Bash mit dem Befehl
`ulimit -c size` die maximale Größe des Corefiles festlegen, die das
Betriebssystem schreibt. Diese muss ich hoch genug wählen, damit das
Corefile für den gewünschten Prozess reicht.

Ich kann den GNU Debugger auf verschiedene Arten starten:

*gdb options program core*
: So starte ich, wenn ich einen Prozess postmortal analysieren will
(mit `core`) oder, wenn ich ein Programm nur beim Ablauf verfolgen will
(ohne `core`). Dabei ist `program` der Name der Programmdatei und
`core` der Name des Corefiles.

*gdb options --args program arguments*
: Hier gebe ich dem
Programm, dass ich beobachten will gleich die Kommandozeilenargumente
beim Aufrauf des GDB mit.

*gdbtui options*
: Das startet den GDB mit einer
Textbenutzeroberfläche, bei der im oberen Teil der aktuelle Quelltext
angezeigt wird und im unteren Teil die Befehle und Ausgaben des GDB.

Von den Optionen, die GDB beim Aufruf mitgegeben werden können, sind die
folgenden für die Fehlersuche relevant, weitere können der Handbuchseite,
der GDB-Texinfo-Datei oder `gdb -help` entnommen werden:

*-c file | -core file*
: Damit gebe ich das Corefile bei den Optionen
an und brauche es nicht mehr nach dem Programmnamen anzugeben.

*-e file | -exec file*
: Gibt das ausführbare Programm an.

*-s file | -symbols file*
: Gibt die Datei mit den Symboltabellen an.
Die Optionen `-s` und `-e` können auch zu `-se`
zusammengefasst werden, wenn die Symboltabellen noch in der
Binärprogrammdatei enthalten sind.

*-help*
: Listed alle Optionen mit einer kurzen Erläuterung auf.

Nachdem ich GDB gestartet habe, steuere ich den Ablauf der Sitzung mit
Textbefehlen. Alle diese Befehle können soweit abgekürzt werden, wie sie
noch eindeutig sind.
Die wichtigsten dieser Befehle für die Fehlersuche sind:

*break function | break file:function*
: So ziemlich als erstes rufe
ich in einer Debuggingsitzung `break main` auf, damit der Debugger
an dieser Funktion anhält und ich anschließend das Programm in Ruhe
analysieren kann. Vor einer Funktion kann ich, durch `:` getrennt
die Datei angeben, falls der Debugger momentan eine andere geladen hat.

*run | run arglist*
: Damit starte ich das Programm im Debugger.
Optional kann ich dem Prozess mit `arglist` einige
Kommandozeilenargumente mitgeben.

*bt*
: Dieser Befehl zeigt den Programmstack an. Bei einer postmortalen
Analyse eines Prozesses rufe ich diesen Befehl als erstes auf, um
herauszubekommen, wo genau das Programm abgestürzt ist.

*print expr*
: Mit `print` lasse ich mir die Werte in den
Variablen und verschiedene andere Datein ausgeben. Dabei kann
`expr` ein komplexer C-Ausdruck sein.

*c*
: Mit `c` (continue) läuft das Programm weiter bis zum
nächsten Haltepunkt oder bis zum Programmende.

*next*
: Dieser Befehl arbeitet die nächste Zeile im Quelltext ab.
Dabei werden Funktionsaufrufe ausgeführt und übersprungen.

*step*
: Auch dieser Befehl arbeitet die nächste Zeile im Quelltext ab,
der Debugger folgt hier allerdings Funktionsaufrufen in das Innere der
Funktion.

*list | list function | list file:function*
: Zeigt die aktuelle
Programmumgebung beziehungsweise die angegebene Funktion im Quelltext.

*help befehl*
: Gibt die Hilfe zu dem angegebenen Befehl aus.

*quit*
: Beendet die Debuggersitzung.

GDB ist ein sehr mächtiges Werkzeug für die Fehlersuche und auch sehr
komplex in der Anwendung. Da die Bedienung nicht einfach ist und es auch
einiger Vorkehrungen für den erfolgreichen Einsatz bedarf, setze ich ihn
eher selten ein, quasi als Ultima Ratio. Trotzdem ist es sinnvoll, sich
gelegentlich hinzusetzen und testweise das eine oder andere Programm im
Debugger zu beobachten und zu analysieren, damit es im Ernstfall, wenn man
darauf angewiesen ist, einfacher von der Hand geht.

## sysstat {#sec-lokal-werkzeuge-sysstat}

Sysstat ist ein Werkzeug zur Einschätzung der Systemperformance.

Üblicherweise wird via cron aller 10 Minuten ein Skript gespeichert, das die
Systemstatistiken sichert. Diese Statistiken können dann mit verschiedenen
Auswertewerkzeugen ausgelesen werden.

Alternativ können diese Werkzeuge auch selbst periodisch die
Performancedaten sammeln und als aktuelle Schnappschüsse ausgeben.

Zur Auswertung mit sysstat stehen die folgenden Werkzeuge zur Verfügung:

*cifsiostat*
: liefert CIFS Statistiken

*iostat*
: liefert CPU- und I/O-Statistiken für Geräte und Partitionen

*mpstat*
: liefert (multi-)prozessorbezogene Statistiken

*nfsiostat*
: liefert NFS-bezogene I/O-Statistiken

*pidstat*
: liefert Statistiken über Linux-Tasks (-Prozesse)

*sar, sadf*
: Sar sammelt, berichtet und sichert Informationen zu
  Systemaktivitäten, sadf gibt die von sar gesammelten Daten in
  verschiedenen Formaten aus.

Die Auswertung der Statistikdaten mit sar wurde bereits in
[Loukides1996](#bib-loukides1996) beschrieben. Da sich die Software seitdem
weiterentwickelt hat, ist ein Blick in die Handbuchseiten unerlässlich.

Für die grafische Auswertung gibt es verschiedene Programme. Ein
Programm, sargraph, wird als Beispiel mit sysstat verteilt. Dieses wertet
die XML-Ausgabe von sadf auf und übergibt sie an gnuplot zur Darstellung.

## acct {#sec-lokal-werkzeuge-acct}

Abrechnungsprogramme spielen eine wichtige Rolle im Gesamtbild der
Performanceoptimierung. Sie liefern einen einfachen Weg herauszufinden, was
ein Rechner macht. Welche Anwendungen laufen, wieviel Systemzeit verbrauchen
diese Programme, wie stark belasten sie das System, und so weiter. Wenn man
die Programme und ihr Verhalten im Großen und Ganzen kennt, kann man sich
an die Strategie machen, um die Performance zu optimieren. Das Programmpaket
acct liefert diese Abrechnungsdaten.

Natürlich belastet das Führen der Statistiken das System zusätzlich. Und
zusätzlichen Plattenplatz benötigen die Statistiken auch. Andererseits: wenn
das System schon deutlich auf das Einschalten der Statistikerfassung
reagiert, arbeitet es bereits in einem Bereich nahe der Belastungsgrenze und
eine Analyse der Systemperformance und entsprechende Maßnahmen sind schon
längst fällig.

Ist das Paket acct installiert, so wird das Accounting meist automatisch
beim Systemstart via accton eingeschaltet. Will man es deaktivieren, reicht
es meist nicht, das über das Startscript auszuschalten, da durch cron in
regelmäßigen Abständen die Protokolle komprimiert werden und dazu das
Accounting ab und wieder angeschaltet wird. Um das Accounting zu
deaktivieren ändert man bei Debian-Systemen in /etc/default/acct die
Variable `ACCT_ENABLE` auf 0.

Die Abrechnugsdaten werden mit dem Programm sa ausgewertet. Dieses Programm
gibt eine Tabelle mit einer Zeile für jedes Programm, mit der Anzahl der
Aufrufe des Programms in der ersten Spalte und die folgenden Bezeichnungen
in den anderen Spalten enthält:

*cpu*
: die Summe von von CPU-System- und -Userzeit in CPU-Minuten

*re*
: die ``wirkliche'' Laufzeit des Programms

*k*
: der durchschnittliche Speicherverbrauch in KByte. Der
  Durchschnitt basiert auf der CPU-Zeit des Programms.

*avio*
: die durchschnittliche Anzahl von I/O-Operationen pro Programmaufruf

*tio*
: die Gesamtzahl der I/O-Operationen

*k*sec*
: das Integral über den Speicher und die CPU-Zeit

*s*
: die Systemzeit

*u*
: die Benutzerzeit

Ganz rechts, ohne Bezeichnung steht der Programmname.  
Ist dieser mit einem Asterisk ('*') gekennzeichnet, ist das Programm als
Daemon gelaufen. Das heißt, es hat `fork()` aufgerufen, aber nicht
`exec()`. Daemon-Prozesse sammeln durch ihre lange Laufzeit auch sehr
viel CPU-Zeit an und verfälschen damit die Werte für den durchschnittlichen
Speicherverbrauch.

Die Tabelle ist nach der CPU-Zeit absteigend sortiert.

Programme, die nur einmalig gelaufen sind, werden in der Zeile
`***other*` zusammengefasst.

Mit den folgenden Optionen kann ich die Ausgabe von sa modifizieren, die
Handbuchseite kennt noch mehr davon:

*-a | --list-all-names*
: Zeigt alle Programme (fasst keine Programme unter
  `***other*` zusammen).

*-b | --sort-sys-user-div-calls*
: Sortiert die Aufrufe nach der
  CPU-Zeit geteilt durch die Anzahl der Aufrufe.

*-d | --sort-avio*
: Sortiert nach der durchschnittlichen Anzahl der
  I/O-Operationen.

*-D | --sort-tio*
: Sortiert nach der Gesamtzahl der I/O-Operationen.

*-i | --dont-read-summary-file*
: Ignoriert die Auswertungsdatei. Mit
  dieser Option zeigt sa die Prozesse seit dem letzten Aufruf von 
  `sa -s`.

*-k | --sort-cpu-avmem*
: Sortiert nach dem durchschnittlichen
  Speicherverbrauch. Dieser Report identifiziert die größten
  Speichernutzer.

*-n | --sort-num-calls*
: Sortiert nach der Anzahl der Aufrufe,
  identifiziert die am häufigsten aufgerufenen Programme.

*-r | --reverse-sort*
: Dreht die Sortierreihenfolge um.

*-s | --merge*
: Fasst die aktuellen Accountingdaten in der
  Auswertungsdatei zusammen.

*-t | --print-ratio*
: Zeigt das Verhältnis von Laufzeit zu CPU-Zeit,
  identifiziert Programme mit sehr viel Leerlauf.

## bonnie++ {#sec-lokal-werkzeuge-bonnie}

Bei jeglicher Art von Performance Tuning ist es essentiell, eine
Bestandsaufnahme vor den Tuning-Maßnahmen und danach zu machen, um sich von
der Wirkung des Tunings zu überzeugen.
Bonnie++ ist ein Programm, mit dem ich die Performance der Lese- und
Schreiboperationen im Dateisystem in Zahlen ausdrücken und damit dann
vergleichen kann.

Dabei gibt das Programm für jeden Test, den es durchführt, zwei Kennzahlen
aus: die geschaffte Arbeit (je mehr, um so besser) und die dafür benötigte
CPU-Zeit (je weniger, umso besser).

Die Tests teilen sich grob in zwei Abschnitte, die man gegebenenfalls auch
überspringen kann. In einem Abschnitt testet bonnie++ den I/O-Durchsatz mit
relativ großen Dateien, wie er ähnlich auch bei Datenbankanwendungen
vorkommt. Im anderen Abschnitt geht es um das Erzeugen, Lesen und Löschen
vieler relativ kleiner Dateien, wie es ähnlich auf Proxy-, Mail- und
News-Servern vorkommt.

In den meisten Fällen ist man eher daran interessiert, das I/O-Verhalten bei
einzelnen Dateisystemen zu beobachten. Bei bestimmten Problemen möchte man
jedoch den Einfluss von gleichzeitigen Dateizugriffen bewerten. Zu diesem
Zweck ist es möglich, mehrere bonnie++ Prozesse synchron zu starten.

Die Ausgabe von bonnie++ kommt, wie schon beim Vorgängerprogramm bonnie als
achtzigspaltiger Text. Zusätzlich gibt bonnie++ die Werte auch noch als
kommaseparierte Werte (CSV) aus, die einfacher weiterverarbeitet werden
können und mehr als 80 Zeichen pro Zeile einnehmen können. Für diese
CSV-Daten gibt es zwei Programme (`bon_csv2html`, `bon_csv2txt`),
die die Daten für die HTML-Ausgabe beziehungsweise das bekannte Textformat
aufbereiten. In deren Handbuchseiten sind die Felder der CSV-Daten
beschrieben.

Eine Warnung will ich noch vorwegschicken, bevor ich mich den Optionen
zu wende, die, wie üblich, in den Handbuchseiten ausführlicher beschrieben
werden.
**Bonnie++ sollte niemals auf aktiven Produktionsmaschinen laufen, da die
Performance durch die Tests sehr stark beeinträchtigt wird.**

### Optionen

*-d dir*
: Das Verzeichnis, in dem die Testdateien angelegt werden.
  Ohne Angabe dieser Option werden die Testdateien im aktuellen
  Verzeichnis angelegt.

*-s size*
: Die Größe der Dateien für die I/O-Performance-Tests. Mit
  einer Größe von 0 wird dieser Test übersprungen.

*-n number*
: Die Anzahl der Dateien für den Dateierzeugungstest. Die
  Anzahl wird als Vielfache von 1024 angegeben. Ist die Anzahl 0, wird
  dieser Test übersprungen. Per Default werden leere Dateien angelegt. Es
  ist möglich, die maximale und minimale Größe der Dateien und die Anzahl
  der Verzeichnisse durch Doppelpunkt getrennt gemeinsam mit der Anzahl
  anzugeben. Details stehen in den Handbuchseiten.

*-x number*
: Anzahl der Testläufe. Damit ist es möglich,
  hintereinander weg mehrere Tests zu machen, die Ergebnisse kommen
  kontinuierlich als CSV-Daten.

*-u user*
: Der Benutzer, unter dem der bonnie++ Prozess laufen soll.
  Bonnie++ kann als normaler Nutzer gestartet werden. Startet man es als
  root, gibt man mit dieser Option besser einen anderen Benutzer vor, um
  Fehler am Dateisystem zu vermeiden.

*-q*
: Mit dieser Option gibt bonnie++ nur die CSV-Daten an STDOUT aus.
  Dateien angelegt.

*-f | -f size*
: Fast Mode Control, überspringt den zeichenweisen
  I/O-Test, wenn kein Parameter ansonsten gibt es die Testgröße für
  zeichenweisen I/O-Test vor (default 20M)

*-b*
: Keine Pufferung der Schreiboperationen, das heisst es wird
  `fsync()` nach jedem Schreiben aufgerufen.

*-q*
: Quiet Mode. Es wird ein Teil der Ausgabe unterdrückt, an STDOUT
  werden nur die CSV-Daten ausgegeben, alles andere an STDERR. Damit ist
  es einfacher, die Ausgabe weiter zu verarbeiten.

*-p number*
: Die Anzahl der der Prozesse, für die Semaphore
  reseerviert werden sollen. Alle Prozesse, die Semaphore mit Option
  `-ys` verwenden, starten synchron.

*-y s*
: Durch Semaphor synchronisiert starten

*-y p*
: Mit Prompt synchronisieren. Bonnie++ startet erst, wenn
  `<RETURN>` eingegeben wurde.

*-D*
: Direct-I/O (`O_DIRECT`) für Massen-I/O-Tests verwenden.
  \item[-z seed] Die Startzahl für den Zufallsgenerator angeben, um den
  gleichen Test zu wiederholen.

*-Z file*
: Zufallsdaten aus der angegebenen Datei verwenden.

### Synchrone Tests

Um mehrere Prozesse mit bonnie++ synchron zu starten, kann ich wie folgt
vorgehen:

    $ bonnie++ -p3
    $ bonnie++ [weitere Optionen] -ys > out1 &
    $ bonnie++ [weitere Optionen] -ys > out2 &
    $ bonnie++ [weitere Optionen] -ys > out3 &

### Signale

Bonnie++ kann mitunter recht lange laufen, vor allem wenn es mit Option
`-x`  seine Tests wiederholt.

Mit SIGINT kann man die Ausführung abbrechen, bonnie++ räumt dann wieder
auf, das heißt, es entfernt die temporären Dateien und Verzeichnisse. Das
kann auch etwas dauern. Durch wiederholtes Senden von SIGINT bricht es auch
das Aufräumen ab.

SIGHUP wird ignoriert, das heißt, wenn es im Hintergrund läuft, bricht es
auch nicht nach Abmelden vom Terminal ab.

## hdparm {#sec-lokal-werkzeuge-hdparm}

Mit hdparm kann ich von der Kommandozeile aus Einfluß nehmen auf die
Schnittstelle zur Festplatte des Rechners. Ich verwende das Programm zum
Feintuning der Festplattenzugriffe aber auch zum Verifizieren und Beheben
von Plattenfehlern. Es arbeitet mit der Kernelschnittstelle des SATA-, PATA-
und SAS-Subsystems zusammen. Auch bei manchen USB-Festplatten kann ich
Parameter mit hdparm verändern. Für einige der Optionen benötige ich eine
aktuelle Kernelversion.

Allgemein sieht der Aufruf von hdparm wie folgt aus:

    hdparm [optionen] [geraet ..]

Es gibt Optionen, mit denen ich Parameter sowohl abfragen als auch setzen
kann (get/set). Bei diesen Optionen gilt, dass sie ohne weiteres Argument
den Parameter abfragen und mit zusätzlichem Argument den Wert entsprechend
setzen.

Rufe ich hdparm ganz ohne Parameter auf, verhält es sich,
als hätte ich die Optionen `-acdgkmur` angegeben.

In der Datei `/etc/hdparm.conf` kann ich die Default-Konfiguration für
hdparm systemweit hinterlegen.

Nachfolgend beschreibe ich die, aus meiner Sicht, wichtigsten Optionen.
Weitere Informationen gibt es, wie fast immer, in den Handbuchseiten.

*-a*
: (get/set) Anzahl der Sektoren für das Vorauslesen (read-ahead)
  im Dateisystem. Damit verbessert sich die Performance beim sequentiellen
  Lesen großer Dateien. Es gibt noch eine, davon separate,
  Read-Ahead-Funktion der Festplatte, diese Funktion unterstützt.

*-A*
: (get/set) Ein- oder Ausschalten der Vorauslesefunktion der Festplatte.
  Mit `-A0` wird es ausgeschaltet, mit `-A1`  eingeschaltet.

*-B*
: (get/set) Einstellen Advanced Power Management (APM)
  Eigenschaften der Platte, soweit diese das unterstützt. Gültig sind
  Werte von 1 (meiste Energieeinsparung) bis 254 (höchste
  I/O-Performance), mit dem Wert 255 wird es ganz abgeschaltet. Werte von
  1-127 erlauben einen Spin-Down der Festplatte, Werte von 128-254
  erlauben das nicht.

*-c*
: (get/set) 32-Bit-Support für (E)IDE ein- oder ausschalten.
  Mit 0 wird dieser Ausgeschaltet, 1 schaltet ihn ein und 3 schaltet den
  32-bit-Support mit speziellem Sync.

  Es geht hierbei um den Transfer via PCI oder VLB zum Hostadapter. Das
  Kabel zur Festplatte hat immer 16 Bit.

*--fibmap dateiname*
: Gibt eien Liste von Blockextents
  (Sektorbereichen), den die Datei auf der Platte belegt.

  Damit kann ich mir die Fragmentierung einer Datei auf der Platte
  ansehen, oder die Blöcke für Fehlertests bestimmen.

  Wenn diese Option verwendet wird, muss sie die einzige sein.

*-g*
: Zeigt die Laufwerksgeometrie (Zylinder, Köpfe, Sektoren), die
  Größe des Gerätes in Sektoren und den Startoffset von Beginn der Platte.

*-i*
: Zeigt Identifizierungsinformationen, die die Kerneltreiber
  während des Systemstarts und der Konfiguration gesammelt haben.

*-I*
: Zeigt die Identifizierungsinformationen, die das Laufwerk liefert.

*-m*
: (get/set) Die Anzahl der Sektoren für multiple Sektor I/O. Mit
  dem Wert 0 wird das abgeschaltet. Die meisten IDE-Festplatten erlauben
  die Übertragung von mehreren Sektoren pro Interrupt. Damit läßt sich der
  System Overhead für Disk I/O um typisch 30 bis 50 Prozent reduzieren. Es
  kann allerdings in seltenen Fällen zu massiven Dateisystemfehlern
  führen.

*--read-sector sektornummer*
: Liest den angegebenen Sektor und
  schreibt den Inhalt in Hex-Darstellung zum Standardausgang. Die
  Sektornummer muss als Dezimalzahl angegeben werden. Hdparm führt einen
  Low-Level-Read für diesen Sektor  aus. Damit kann diese Funktion als
  definitiver Test, ob ein Sektor schlecht ist, genommen werden. Um den
  Sektor durch die Platte ersetzen zu lassen, kann man die Option
  `--write-sector` verwenden.

*-t*
: Nimmt die Zeit von Lesezugriffen für Benchmarks und
  Vergleichsmessungen. Um brauchbare Werte zu erhalten, muss man diese
  Funktion mindestens zwei mal bei einem ansonsten inaktiven System (keine
  anderen aktiven Prozesse) und genügend freiem Hauptspeicher ausführen. 
  Diese Funktion zeigt, wie schnell Daten ohne den Overhead des
  Dateisystems gelesen werden können.

*-T*
: Nimmt die Zeit von Cache-Read-Zugriffen. Auch diese Funktion
  sollte mindestens zwei mal bei ansonsten inaktivem System wiederholt
  werden. Das zeigt den Durchsatz von Prozessor, Cache und RAM.

*--write-sector sektornummer*
: Schreibt Nullen in den Sektor. **Sehr gefährlich!** Irrt man
  sich in der Sektornummer, werden möglicherweise vitale Informationen des
  Dateisystems überschrieben. Die Sektornummer wird als Dezimalzahl
  angegeben.
  Diese Funktion kann zum Anstoßen der automatischen
  Reparatur des Sektors durch die Festplatte verwendet werden.
  Sinnvollerweise vergewissert man sich vorher mit der Option
  `--read-sector`, das man es wirklich mit einem defekten Sektor zu
  tun hat.

*-W*
: (get/set) Zeigt beziehungsweise modifiziert das Write Caching
  des IDE/SATA Laufwerks. 1 bedeutet, dass es eingeschaltet ist.

*-z*
: Zwingt den Kernel, die Partitionstabelle neu zu lesen.

In der Datei /etc/hdparm.conf kann die Default-Konfiguration für hdparm
hinterlegt werden. Diese Datei ist gut kommentiert, so dass ich mir weitere
Erläuterungen hier spare.

## Notizen

*   Wie installiere ich Software?

*   Was für eine Kernelschnittstelle nutzt strace?

*   Strace-Skript: Datum, Kommandozeile, Umgebung, Benutzer,
    Standardeingabe, Strace-Ausgabe

*   Diskussion: wann ltrace, wann strace

*   Was bedeutet aktive / inactive bei Memory? (vmstat)
