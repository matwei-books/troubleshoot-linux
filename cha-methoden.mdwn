# Methoden, Heuristiken und Modelle {#cha-methoden}

Methoden, Heuristiken und Modelle sind das geistige Rüstzeug, das
unentbehrlich ist für jeden Problemlöser.

In diesem Kapitel will ich etwas näher auf diese eingehen und die folgenden
Fragen beantworten.
Wofür kann ich diese nutzen?
Welches Ergebnis kann ich von ihnen erwarten?
Wann setze ich sie ein?

## Begriffe

Im Duden oder anderen Nachschlagewerken kann ich umfangreiche Erklärungen für
diese drei Begriffe finden, die ich hier nicht detailliert wiedergeben werde.

Um aber eine gemeinsame Sprache zu finden, lege ich hier kurz dar, was ich
meine, wenn ich in diesem Buch von *Methoden*, *Heuristiken* und *Modellen*
spreche.

Methode
: Wenn ich hier von einer Methode spreche, meine ich ein auf Regeln aufbauendes
  Verfahren um konkrete Erkenntnisse oder praktische Ergebnisse zu erlangen.
  Eine Methode kann ich nur unter bestimmten Voraussetzungen sinnvoll einsetzen.
  Sie liefert mir dann jedoch relativ klar definierte Ergebnisse beziehungsweise
  Erkenntnisse.

Heuristik
: Unter Heuristik verstehe ich ebenfalls ein Verfahren zur Gewinnung neuer
  Erkenntnisse.
  Im Gegensatz zur Methode bekomme ich aber keine klar definierten Ergebnisse,
  sondern bestenfalls Anhaltspunkte, die mir eine Richtung für die weitere
  Untersuchung anzeigen.

Modell
: Unter einem Modell verstehe ich hier ein vereinfachtes Abbild der
  Wirklichkeit, dass bestimmte, für die Betrachtung wesentliche Merkmale
  korrekt abbildet und andere ignoriert.
  Ein und dieselbe Situation kann ich mit verschiedenen Modellen beschreiben.
  Welches Modell ich wähle, hängt davon ab, welche Eigenschaften ich
  untersuchen will.

X> Nimm den Duden, ein anderes Nachschlagewerk oder Wikipedia und schlage die
X> Begriffe *Methode*, *Heuristik* und *Modell* nach.
X> Lies auch die Erklärungen zu angrenzenden Begriffen.
X> Vergleiche diese Begriffsbestimmungen mit den hier angegebenen.
X> Das ganze sollte nicht länger als 15 Minuten in Anspruch nehmen.

## Entscheidungsbaum {#sec-methoden-entscheidungsbaum}

Wenn ich auf ein neues Problem treffe, versuche ich es so schnell wie
möglich zu charakterisieren, um die nächsten Schritte zu seiner Behebung
herauszufinden.
Dabei helfen mir Entscheidungsbäume. Programmierern ist so etwas
wahrscheinlich als Programmablaufplan bekannt. Mein grundlegender
Entscheidungsbaum bei der Fehlersuche sieht immer so aus:

![Allgemeiner Entscheidungsbaum](images/eb-allgemein-drakon.png)

Grundsätzlich werde ich nur tätig, wenn eine der Fragen mit nein beantwortet
wird und habe damit fast alle Probleme abgedeckt.

Die erste Frage, ob der Fehler reproduzierbar zu beobachten ist, erscheint
vielleicht trivial, entscheidet aber, ob ich den Fehler überhaupt
strukturiert eingrenzen oder nur eine Vermutung anstellen kann.
Wenn ich eine Anfrage via E-Mail bekomme und den Fehler bei mir nicht
reproduzieren kann, oder wenn mich ein Kunde anruft mit Netzproblemen und
ich nicht auf sein Netz zugreifen kann, ist damit nicht gemeint. In diesen
Fällen kann ich, auch wenn ich selbst nicht direkt auf das Problem schauen
kann, trotzdem anhand des Entscheidungsbaumes zurückfragen. Was ich mit
dieser Frage ausschließen will, sind intermittierende Probleme. Probleme,
die auftauchen aber sich der Analyse entziehen. Die scheinbar aus dem Nichts
kommen und weg sind, sobald ich mich ihnen zuwende. Natürlich kann ich
die meisten dieser Probleme auch strukturiert bearbeiten. Aber erst muss ich
sie dingfest machen und gezielt reproduzieren können. Nur dann kann ich
sicher sein, dass eine vielleicht zufällig gefundene oder erratene Abhilfe
auch wirklich wirksam ist. In diesen Fällen bleibt mir nichts übrig als
soviel wie möglich Daten zum Auftreten dieser Fehler zu sammeln und dann mit
Heuristiken weiter zu sehen.

Habe ich ein intermittierendes Problem ausgeschlossen, ist meine nächste
Frage, ob überhaupt noch etwas funktioniert oder es sich um einen
Totalausfall handelt. Auch diese Frage erscheint vielleicht trivial, aber
das ist letztendlich der Zweck eines Entscheidungsbaumes: das die richtigen
(möglichst einfach zu beantwortenden) Fragen im richtigen Moment gestellt
werden. Manchmal ist es so, dass ein Anwender berichtet, dass eine bestimmte
Funktion eines Programmes nicht funktioniert und sich irgendwann
herausstellt, dass der ganze Rechner eingefroren ist und zwar noch den
letzten Bildschirm zeigt, aber weder auf Tastatur, Maus noch
Netzwerkzugriffe reagiert. Ein anderes Mal kommt die Meldung, dass das
Internet nicht geht (Totalausfall) und auf die Bitte ein oder zwei andere
Websites zu besuchen, sich herausstellt, dass doch nur die eingestellte
Startseite des Browsers betroffen ist. Darum versuche ich mit dieser Frage
herauszufinden, ob es sich um einen Totalausfall handelt, der anders
behandelt werden muß als ein Teilausfall.

Wenn ich einen Totalausfall ausgeschlossen habe, frage ich als nächstes, ob
alle für das Problem relevanten Dienste funktionieren. Es erfordert schon
verhältnismäßig viel Detailkenntnisse zur betreffenden Problemzone, um zu
entscheiden, ob ein Dienst für das Problem relevant ist oder nicht. Im
Zweifelsfall kontrolliere ich lieber einen Dienst mehr. Hier geht es vor
allem darum, einen Überblick zu bekommen, was funktioniert und was nicht und
dann über Abhängigkeiten der Teilsysteme sich an den oder die Urheber des
Problems heranzutasten. Dabei gilt es immer im Hinterkopf zu behalten, dass
es zwar meist einen konkreten Auslöser für ein Problem gibt, oaber oft
mehrere Ursachen. Eine Möglichkeit, diese Frage zu beantworten, ist zum
Beispiel verschiedene Funktionen einer Software auszuprobieren, verschiedene
Netzdienste und Netzziele zu testen. Hierbei kann ein Monitoringsystem wie
Nagios etc. gute Dienste leisten, wenn es entsprechend aufgesetzt ist.

Habe ich mich davon überzeugt, dass alle notwendigen Dienste prinzipiell
funktionieren, kann ich die nächste Frage, ob es schnell genug ist, stellen.
Diese Frage ist nicht leicht zu beantworten, da jeder seine eigene
Vorstellung von schnell genug hat. Gibt es SLA, können diese vielleicht bei
der Beantwortung der Frage helfen. Bei nicht interaktiven Aufgaben, wie
Datensicherungen, Batchjobs etc. kann man die Gesamtlaufzeit betrachten und
an Hand dieser entscheiden, ob es schnell genug ist, oder nicht. Bei
Dateiübertragungen kann man an Hand von Bandbreite, Netzauslastung und
Übertragungsdauer überschlagen, ob es Performanceprobleme gibt oder nicht.
Bei interaktiven Programmen oder Netzwerkdiensten zählt meist nur die
Antwortzeit des Systems, die im Bereich von Sekundenbruchteilen liegen
sollte. Komme ich zu dem Schluss, dass es sich um ein Performanceproblem
handelt, gehe ich dieses an. Anderenfalls begründe ich, warum es sich meiner
Meinung nach um kein Performanceproblem handelt. Dabei kann mir eine
sogenannte Baseline helfen.

Alles in allem habe ich mit den vier Fragen dieses Entscheidungsbaumes eine
Richtschnur, die mir hilft, ein Problem herunterzubrechen und mich dem
wichtigsten Bereich zu widmen, bevor ich mich in den Details verliere.

Dabei muss ich den Entscheidungsbaum nicht zwangsläufig von oben nach unten
verwenden. Wenn mir zum Beispiel ein Netzwerk-Performanceproblem gemeldet
wird, ist es hilfreich, wenn ich mich zunächst davon überzeuge, dass alle
Dienste die für das Problem relevant sind, auch funktionieren. Das heißt,
ich gehe in diesem Fall von unten - dem gemeldeten Performanceproblem -
einen Schritt nach oben um sicher zu sein, dass meine folgenden Überlegungen
auf einer gesicherten Basis stehen. Zum Beispiel kann ein ausgefallener
DNS-Server durch Redundanz zwar kompensiert werden, aber trotzdem zu
Verzögerungen durch Timeouts führen, die dann als Performanceprobleme
wahrgenommen werden können.

## Bisektion {#sec-methoden-bisektion}

Die Bisektion, auch Intervallhalbierungsverfahren genannt, wird verwendet um
bei einem Fehler, der auf einer längeren Strecke - zum Beispiel bei einer
Netzwerkverbindung über mehrere Hops - oder über einen längeren Zeitraum
auftritt, den Punkt, an dem der Fehler erstmalig auftritt, so schnell wie
möglich zu ermitteln. Diesen Punkt suche ich, da er mir vermutlich Hinweise
auf die Ursache geben kann.

Das Intervall kann örtlich sein - zum Beispiel bei einer Datenübertragung
über mehrere Hops - oder zeitlich - zum Beispiel, wenn sich der Fehler in
Logfiles zeigt und ich den Zeitpunkt des ersten Auftretens über viele
Logdateien hinweg suche.

Das Verfahren selbst ist sehr einfach. Anstatt das Intervall sequentiell in
einer Richtung abzuschreiten, wird das Intervall halbiert und von den
entstehenden Teilintervallen dasjenige untersucht, dessen Grenzen sich
unterscheiden. Bei diesem Teilintervall fährt man mit der Bisektion fort.

Wenn ich zum Beispiel einen Rechner in einem weit entfernten Netz zwar via
Ping erreichen kann, aber zum Beispiel nicht mit Port 25, dann kann ich 
zunächst untersuchen, ob Datenpakete zu Port 25 beim Sender rauskommen und
ob sie beim Empfänger ankommen. Kann ich die Datenpakete beim Sender
nachweisen, aber beim Empfänger nicht, dann suche ich etwa auf der Hälfte
der Strecke, ob diese Datenpakete nachzuweisen sind. Je nachdem, ob die
Datenpakete dort auftreten oder nicht, halbiere ich dann die Strecke zum
Empfänger oder zum Sender. 

## Korrelation {#sec-heuristik-korrelation}

Mit einer Korrelation kann ich eine Beziehung zwischen zwei oder mehreren
Merkmalen, Ereignissen oder Zuständen beschreiben. Wichtig ist dabei, zu
beachten, dass diese Beziehung kausal sein kann aber nicht muss. Im
mathematischen Sinne beschreibt die Korrelation einen statistischen
Zusammenhang im Gegensatz zur Proportionalität, die einen festes Verhältnis
beschreibt.

Oft will ich den Phi-Koeffizient oder Vierfelder-Korrelationskoeffizient für
zwei dichotome Merkmale ermitteln.
Um diesen zu berechnen stelle ich eine Kontingenztafel auf, in der ich die
gemeinsame Häufigkeit der Merkmale aufstelle.

|                         | kein Fehler | Fehler |
|-------------------------|-------------|--------|
| Merkmal trifft zu       |     A       |    B   |
|-------------------------|-------------|--------|
| Merkmal trifft nicht zu |     C       |    D   |

A, B, C, D stehen für die Anzahl der Ereignisse, bei den der Fehler auftrat
beziehungsweise nicht auftrat und das Merkmal A zutraf oder nicht.
Als Werte für A, B, C und D kann ich Zeiträume summieren, oder zu regelmäßigen
Zeitpunkten ermitteln, welcher Fall zutrifft und die entsprechende Variable
hochzählen.

Der Phi-Koeffizient ermittelt sich dann aus:

{$$}
\phi = \frac{A D - B C}{\sqrt{(A+B) (C+D) (A+C) (B+D)}}
{/$$}

Im einfachsten Fall kann ich eine Korrelation selbst sehen, zum Beispiel, wenn
immer die Verbindung zum Netz A wegfällt, sobald ich die Verbindung zum Netz B
umschalte.
Das sagt zwar nichts aus über die eigentliche Ursache, aber es gibt mir zum
einen die Möglichkeit, das Problem kurzfristig temporär aus dem Weg zu
schaffen und zum anderen, wenn die Zeit geeignet ist, das Problem
hervorzurufen, um es gründlich zu studieren.

Eine andere Klasse von Problemen, bei denen mir Korrelationen zumindest
weiterhelfen, sind sogenannte intermittierende Probleme, die sich dem
andersartigen Zugang entziehen.
Bei diesen Problem hilft mir am Anfang nur, so viele Daten über das betroffene
Gesamtsystem wie möglich zu sammeln.
Bei der Analyse dieser Daten hilft mir dann die Kovarianzanalyse, das heisst,
ich vergleiche jeweils paarweise verschiedene beobachtete Systemvariablen und
ermittle die Kovarianz oder den Korrelationskoeffizienten.
Wichtig dabei ist, dass ich immer die zusammengehörigen Daten in Beziehung
setze.
Da das meist über die Uhrzeit passiert, sorge ich also entweder im Vorfeld für
gleichlaufende Uhren, oder ich muss den Zeitoffset bestimmen und rausrechnen.

Ein Programm, das sehr hilfreich für die Kovarianzanalyse ist, wurde in
[WSA2011](#bib-wsa2011) beschrieben.

Wichtig bei allen Korrelationsanalysen ist, sich vor Augen zu halten, dass
uanbhängige Merkmale immer eine Kovarianz von 0 haben.


## Abkürzungen und Umwege {#sec-heuristik-abkuerzung-umweg}

Im Laufe der Zeit, wenn ich einige Erfahrungen mit den Systemen gesammelt
habe, kann ich bei etlichen Fehlern intuitiv sagen, woran es liegt.
Damit kann ich mir erhebliche Zeit bei der Fehlersuche ersparen.
Ich muss jedoch trotzdem im Auge behalten, ob meine Annahmen auf einer realen
Grundlage beruhen, oder ob mich meine Intuition hier in die Irre führt.

Das heißt, dass ich jedes Mal, wenn ich eine Abkürzung nehme, mich
vergewissern muss, dass die Voraussetzungen dafür stimmen.

### Abkürzungen

Eine Möglichkeit, die Fehlersuche abzukürzen, ist durch simple Korrelation.
Bei der Aufnahme des Fehlers frage ich, wann der Fehler das erste Mal bemerkt
wurde und wann es das letzte Mal funktioniert hatte.
Im Rahmen der Fehlersuche, schaue ich nach, was am System in diesem Zeitraum
geändert wurde und überlege für jede Änderung, ob diese den beschriebenen
Fehler hervorrufen könnte.
Dazu benötige ich natürlich eine aussagefähige Protokollierung der Änderungen
am System.
Und der Fehler sollte so schnell, wie möglich gemeldet werden, damit der
Zeitraum, den ich in Betracht ziehe, nicht zu groß wird.

### Umwege

#### Probe und Gegenprobe

Jeder Test, der erfolgreich ist, sollte durch eine geeignete Gegenprobe
evaluiert werden, die bestätigt, dass der Test auch versagen kann. Das gleiche
gilt für fehlgeschlagene Tests. Diese müssen evaluiert werden, ob sie
funktioniern können.

Wenn ein Verbindungsversuch auf einem Rechner fehlschlägt, versuche ich den
gleichen Versuch von einem anderen Rechner aus um nachzuweisen, dass er hätte
funktionieren können. Das hat mich schon häufig davor bewahrt, einen
Netzwerkfehler zu vermuten, wenn lediglich ein Paketfilter auf dem Zielrechner
die Verbindung unterbunden hatte.

## Modelle

### Prozessmodell

Wenn ich Fehler auf Linux- oder Unix-Systemen suche, ist es vorteilhaft, das
UNIX-Prozessmodell zumindest in groben Zügen zu verstehen.

Bevor ich auf dieses eingehe, will ich kurz auf die Begriffe Programm und
Prozess eingehen, da diese im allgemeinen Sprachgebrauch oft vermischt werden.

Ein *Programm* ist nicht mehr als eine Reihe von Instruktionen für den
Prozessor eines Rechners, die so angeordnet sind, dass deren Abarbeitung mehr
oder weniger sinnvolles Verhalten des Rechners ermöglicht.
Das Programm im Sinne des hier besprochenen Prozessmodels ist immer auf den
entsprechenden Prozessor zugeschnitten.
Zwar spricht man auch bei Shell-, Perl- oder sonstigen Skripten hin und wieder
von Programmen, im Sinne der UNIX-Prozessmodells sind dann aber die
entsprechenden Interpreter, die Programme, welche von eben jenen Skripten
gesteuert werden können.

Ein *Prozess* demgegenüber ist ein komplexeres Konstrukt, das über spezielle
Datenstrukturen im Kernel identifiziert wird, Zugang zu bestimmten Dateien im
Dateisystem hat, Rechenzeit und Hauptspeicher zugeteilt bekommt und ein
Programm abarbeitet.
Ein Prozess wird immer durch eine PID identifiziert, über zugordnete Benutzer-
und Gruppenidentitäten (UID, GID) werden seine Zugriffsrechte auf Ressourcen
bestimmt.

Wenn jemand sagt, Programm xyz startet, ist damit gemeint, ein Prozess führt
Programm xyz aus.
Bildlich kann man einen Prozess mit einem Lebewesen vergleichen und ein
Programm mit seiner DNA.

Der Lebenszyklus eines Prozesses mit Ausnahme des allerersten, vom Kernel
gestarteten Prozesses beginnt immer mit dem `fork()` Systemaufruf.
Dieser Aufruf macht nichts anderes, als eine exakte Kopie des aufrufenden
Prozesses anzulegen.
Damit haben wir dann zwei vollkommen identische Prozesse, die sich erst nach
Rückkehr des `fork()` Systemaufruf unterscheiden, und zwar im Rückgabewert
desselben.
Beim aufrufenden Prozess (Parent oder Elternprozess genannt) gibt `fork()` die
PID des Klonprozesses zurück.
Beim geklonten Prozess liefert es `0`.
Das ist die einzige Möglichkeit für das abgearbeitete Programm, zwischen
diesen beiden Prozessen zu unterscheiden.

Jenachdem, welches Programm gerade an welcher Stelle ausgeführt wurde, werden
anschließend beide Prozesse das gleiche Programm ausführen (wie zum Beispiel
die Worker-Prozesse beim Apache HTTP-Dämon) oder ein Prozess beginnt ein
anderes Programm abzuarbeiten.
Das führt uns zum nächsten wichtigen Bestandteil, dem Laden eines Programmes
für die Abarbeitung.
Nachdem ein Prozess neu erzeugt wurde, arbeitet er zunächst das gleiche
Prozess wie sein Parent ab.
Um ein anderes Programm auszuführen, verwendet der Prozess den `exec()`
Systemaufruf.
Damit wird der Hauptspeicher des Prozesses mit dem Abbild des neuen Programms
überlagert. 
Das neue Programm wird ab einem definierten Eintrittspunkt abgearbeitet.
Programmargumente und Umgebungsvariablen werden im Hauptspeicher übergeben.
Dateideskriptoren (offene Dateien) bleiben über einen `exec()` Systemaufruf
unverändert.
Da im Hauptspeicher nun das neue Programm ist, gibt es kein Zurück zum alten.

Bleibt als letzter Teil im Lebenszyklus eines UNIX-Prozesses das Ende zu
besprechen.
Ein Prozess kann sich durch den `exit()` Systemaufruf selbst beenden oder vom
Kernel beendet werden (zum Beispiel beim SIGKILL oder Schutzverletzungen).
In jedem Fall bleibt die Prozessstruktur im Kernel erhalten, bis der Parent
den Prozessstatus mit `wait()` abfragt.
Versäumt der Parent-Prozess die Abfrage mit `wait()`, ist das zum Beispiel im
Prozesslisting mit *ps* sichtbar.
Wird ein Parent vor dem Child beendet (z.B. bei Dämonprozessen, die die
Kontrolle sofort an die aufrufende Shell zurückgeben), übernimmt `init`, der
erste vom Kernel gestartete Prozess die Funktion des Parent und fragt deren
Status mit `wait()` ab.

X> Suche im Internet zum Thema *unix process model* und schaue in den
X> Ergebnissen nach Beispiel-Code. Kompiliere diesen und beobachte, was beim
X> Start der Programme passiert.

### Schnittstellen beim Aufruf von Programmen

Bei der Fehlersuche auf Linux-Servern bewege ich mich fast die gesamte Zeit
auf der Kommandozeile und rufe die verschiedensten Programme auf.
Für das Aufrufen von Programmen selbst, brauche ich keine weiteren Kenntnisse.
Bei der Fehlersuche, ist es auf jeden Fall von Vorteil, wenn ich genau weiß,
wie ich mit einem Programm kommunizieren kann.
Das Buch von Reinhard Fößmeier [[Foessmeier1991]](#bib-foessmeier1991)
erläutert die verschiedenen Schnittstellen von Programmen unter UNIX sehr
ausführlich.

#### Kommandozeile

Die Kommandozeile selbst bezeichnet Fößmeier als K-Schnittstelle.
Diese bezeichnet eine Reihe von Parameter, die als C-Strings übergeben werden
und die jedes Programm beim Aufruf übergeben bekommt.
Diese werden von *strace* als Parameter beim `execve()` Systemaufruf
angezeigt.

Mit dieser Schnittstelle kann ich nur in einer Richtung kommunizieren, von der
Aufrufumgebung zum Programm.

Wenn ich (Shell-)Skripts schreibe, kann ich auf diese Parameter mit den
Variablen `$0`, `$1`, ... zugreifen. In `$#` habe ich die Anzahl der beim
Aufruf übergebenen Parameter.

In C-Programmen bekommt die Funktion `main()` als ersten Parameter die Anzahl
und als zweiten Parameter einen Zeiger auf das Parameterfeld.

Prinzipiell gibt es keine Regeln für die Gestaltung dieser Parameter. Es haben
sich aber einige Konventionen herausgebildet, die von sehr vielen Programmen
eingehalten werden und für die es Unterstützung bei der Programmierung durch
einige Bibliotheken gibt. Nach dieser Konvention werden Parameter in folgende
Gruppen eingeteilt:

Optionen
: bestehen oft aus einem Bindestrich, dem ein einzelnes Zeichen
  folgt. Diese werden unterschieden in Wertoptionen, denen ein Wert
  nachfolgt und Schaltoption, deren bloßes Vorhandensein ausreicht.

  Neben den alten Optionen, die aus einem Zeichen bestehen, gibt es seit
  geraumer Zeit sogenannte lange Optionen, die oft mit zwei Bindestrichen,
  manchmal mit einem `+` und, seltener, mit einem Bindestrich eingeleitet
  werden.

Werteparameter
: folgen einer Wertoption und beinhalten den zur Option gehörigen Wert.
  Diese Werteparameter können bei den kurzen Optionen direkt anschließen oder
  als nächster Parameter übergeben werden.

  Bei den langen Optionen werden Werteparameter entweder mit einem `=` direkt
  an die Option angefügt oder als nächster Parameter angegeben.

Namensparameter
: stellen oft Namen von Dateien dar, die vom Programm bearbeitet werden
  sollen.

Um Verwechslungen von Namensparametern mit Optionen auszuschließen, gibt es
die Konvention, dass alle Parameter nach `--` als Namensparameter verarbeitet
werden, um so auch Dateien bearbeiten zu können, deren Name mit einem
Bindestrich beginnt.

#### Umgebungsvariablen

Die Umgebungsvariablen werden bei Fößmeier als U-Schnittstelle bezeichnet.
Im Gegensatz zu K-Schnittstelle, deren Parameter positionsabhängig sind,
können diese Variablen nur über ihren Namen angesprochen werden.

Auch mit dieser Schnittstelle kann ich nur von der Aufrufumgebung in Richtung
aufgerufenes Programm kommunizieren.

In Shell-Programmen kann man auf diese Variablen, genau wie auf lokale
Variablen über den Namen mit vorangestelltem `$` zugreifen.

Das Setzen der Umgebungsvariablen für ein aufgerufenes Programm ist abhängig
von der verwendeten Shell. Bei der Bourne-Shell und den davon abgeleiteten
geschieht das durch einfache Zuweisung `variable="wert"`. Die
Anführungszeichen um den Wert sind nur notwendig, wenn dieser Leerzeichen
enthält. Für die Übergabe an aufgerufene Programme gibt es zwei Möglichkeiten:

*   Die Variable wird mit der Anweisung `export` gekennzeichnet, was für die
    Shell dem Befehl gleich kommt, diese Variable an alle nachfolgend
    aufgerufenen Programme zu übergeben.

{line-numbers=off,lang="text"}
        TERM=vt100
        export TERM
        ssh server1

*   Die Variable wird unmittelbar vor Aufruf des Programmes (in der selben
    Zeile) gesetzt. In diesem Fall gilt der Variablenwert nur für diesen, mit
    dieser Zeile gestarteten Prozess.

{line-numbers=off,lang="text"}
        TERM=vt220 ssh server2

Da die Kommunikation nur in einer Richtung geht, gibt es keine Möglichkeit,
für ein aufgerufenes Programm, die Umgebungsvariablen des aufrufenden
Programmes (zum Beispiel der Shell) zu ändern. Dafür greift man auf einen
Trick zurück, und zwar indem die Shell die Ausgabe des aufgerufenen Programms
interpretiert und dieses die Variablenzuweisung in die Standardausgabe
schreibt.

{line-numbers=off,lang="text"}
    $ echo $abc
    $ eval $(echo abc=def)
    $ echo $abc
    def

#### Rückgabewert

Wenn ein Prozess durch Aufruf von `exit()` endet, kann er einen ganzzahligen
Wert als Statuscode angeben. Dieser Statuscode und der Zeitpunkt zu dem der
Prozess endet bilden die sogenannte R-Schnittstelle.

Der Statuscode wird zum Beispiel von der Shell und dem Programm *make*
ausgewertet. Der Statuscode `0` wird dabei als erfolgreiche Beendigung des
Programms gewertet, alle anderen Codes deuten auf ein Problem und sind
abhängig vom aufgerufenen Programm.

In der Shell kann ich den Statuscode des letzten aufgerufenen Programms in der
Variable `$?` abfragen. In C-Programmen zum Beispiel durch Aufruf der Funktion
`wait()`.

Wenn ich ein Shell-Skript mit der Option `-e` starte, bricht die Shell ab,
sobald ein aufgerufenes Programm einen anderen Rückgabewert als `0` hat. Das
ist auch das Standardverhalten von `make`.

#### Datenströme

Die S-Schnittstelle fasst alle Schnittstellen zusammen, die aus einem Strom
von Zeichen bestehen. Das können die sogenannten Standard-Datenströme sein
(STDIN, STDOUT, STDERR) oder weitere geöffnete Dateien, Sockets oder Pipes.

Auf der Kommandozeile sind insbesondere die Standard-Datenströme relevant,
da einzelne Programme damit verkettet werden können, so dass jedes folgende
Programm die Standardausgabe (STDOUT) des vorigen Programms als
Standardeingabe (STDIN) bekommt.

Im folgenden Beispiel liest das Programm `tail` fortlaufend aus einer Logdatei
und übergibt seine Ausgabe dem Program `grep` als Eingabe, welches alle
Zeilen ignoriert bis auf diejenigen, die das Wort *CRON* enthalten:

{line-numbers=off,lang="text"}
    $ tail -f /var/log/syslog | grep CRON

Prinzipiell kann über eine S-Schnittstelle ein unbegrenzter Strom von Daten
übertragen werden, zum Beispiel bei zwei über eine Pipe verbundenen Prozessen,
wie in obigem Beispiel.

Mit dem *Dateiende* (EOF) kann zu einem Datenstrom übermittelt werden, dass
keine weiteren Daten mehr folgen. In diesem Fall kann ein Programm angemessen
reagieren und sich zum Beispiel beenden

{line-numbers=off,lang="text"}
    $ zcat /var/log/syslog* | grep CRON

In diesem Beispiel liest das Programm `zcat` alle Dateien aus dem Verzeichnis
*/var/log*, deren Name mit *syslog* beginnt (komprimiert und unkomprimiert)
und sendet ihren Inhalt wie im Beispiel davor an `grep`. Wenn der
unkomprimierte Inhalt aller Dateien zur Standardausgabe geschickt sind,
beendet sich `zcat`, wodurch seine Standardausgabe geschlossen wird. Das
übermittelt der Kernel als *Dateiende* bei STDIN an `grep`, welches sich
daraufhin ebenfalls beendet.

Wenn ich Daten von Hand in die Standardeingabe eines Prozesses schreibe, kann
ich durch Eingabe von *<CTRL>-D* die Dateiendeinformation für den lesenden
Prozess erzeugen.

#### Dateien

Die N-Schnitsstelle entspricht dem Inode, der eine Datei in einem Dateisystem
beschreibt. Diese Schnittstelle enthält Metainformation über die betreffende
Datei, aber nicht die Daten selbst.

Bei manchen Gerätedateien ist es möglich, darüber Einstellungen an den
betreffenden Geräten vorzunehmen.

#### Text-Terminal

Die T-Schnittstelle bezeichnet das Treiberprogramm für das Text-Terminal über
das ich meine Eingaben mache und die Ausgaben angezeigt bekomme. Dabei kann
das Terminal eine normale Computerkonsole sein, eine serielle Konsole oder ein
Programm wie Xterm.

Diese Schnittstelle sorgt zum Beispiel dafür, dass beim traditionellen
Zeilenendezeichen (LF) automatisch ein Wagenrücklauf (CR) ausgeführt wird,
damit die nächste Zeile wieder am linken Rand beginnt.
Im sogenannten Cooked Mode sammelt diese Schnittstelle meine Eingabe bis zum
*<RETURN>* um sie dann als ganze Zeile an den Prozess zu schicken.

Auf der Kommandozeile kann ich über das Programm `stty` auf diese
Schnittstelle zugreifen und sie bearbeiten. In C-Programmen verwende ich die
Funktion `ioctl()`.

### OSI-Modell

Ein wichtiges Modell für die Betrachtung von Netzwerkverbindung ist das *Open
Systems Interconnection Model*.
Dieses dient als Referenzmodell für Netzwerkprotokolle und ist als
Schichtenmodell ausgeführt.
Es gibt keine Implementierung des OSI-Modells, dieses dient lediglich der
Einordnung realer Protokoller und der Kommunikation darüber.
In diesem Modell gibt es sieben aufeinanderfolgende Schichten mit jeweils
begrenzten Aufgaben.
Jede Instanz einer Schicht nutzt die Dienste der Instanzen der nächsttieferen
Schicht und stellt ihre Dienste den Instanzen der nächsthöheren Schicht zur
Verfügung.
Die folgenden Dienste sind im OSI-Modell definiert:

|   | deutsche Bezeichnung   | englische Bezeichnung |
|---|------------------------|-----------------------|
| 7 | Anwendungsschicht      | application layer     |
| 6 | Darstellungsschicht    | presentation layer    |
| 5 | Sitzungsschicht        | session layer         |
| 4 | Transportschicht       | transport layer       |
| 3 | Vermittlungsschicht    | network layer         |
| 2 | Sicherungsschicht      | data link layer       |
| 1 | Bitübertragungsschicht | physical layer        |

Die Instanzen auf Sender und Empfängerseite müssen nach festgelegten Regeln
(dem Protokoll) arbeiten und bilden dann eine logische horizontale Verbindung
über diese Schicht. Die in der gleichen Schicht definierten Netzwerkprotokolle
mit klar definierten Schnittstellen sind untereinander austauschbar.

Reale Protokolle bilden mitunter mehrere Schichten des OSI-Modells ab. Zum
Beispiel:

*   Ethernet die Schichten 1 und 2

*   IP, ICMP, IGMP die Schicht 3

*   TCP, UDP die Schicht 4

*   HTTP, SMTP, LDAP die Schichten 5, 6, und 7

Betrachte ich die Kopplungselemente in einem Computernetzwerk, so decken die
heute kaum noch gebräuchlichen Hubs und Repeater die Schicht 1 ab, Bridges und
Switche die Schichten 1 und 2, Router die Schichten 1 bis 3 und schließlich
Protokoll-Gateways und Content-Switche für die Lastverteilung die Schichten 1
bis 7.

### Zustände einer TCP-Verbindung

Ich betrachte hier die Zustände einner TCP-Verbindung, weil TCP vermutlich das
am häufigsten im Netz vorkommende Protokoll ist.
Außerdem ist es komplex genug, um sich wenigstens mit den grundlegenden
Interna zu beschäftigen und das Verhalten des Protokolls im Störungsfall
einschätzen zu können.

#### Verbindungsaufbau

Beim Aufbau einer TCP-Verbindung haben wir immer eine passive Seite
(üblicherweise der Server, bei FTP auch manchmal der Client) und eine aktive
Seite.
Die passive Seite befindet sich im Zustand LISTEN.

A> Den Zustand der TCP-Verbindungen auf einem Rechner kann man sich sehr gut
A> mit dem Befehl
A>
A>     $ netstat -ant
A>
A> anzeigen lassen.

Ein erfolgreicher Verbindungsaufbau benötigt drei Datenpakete und geht wie
folgt vonstatten:

XXX hier das Diagramm TCP-Verbindungsaufbau einfügen

Der Client sendet ein SYN-Paket (das ist ein TCP-Datagramm mit gesetztem
SYN-Flag) und geht in den Zustand *SYN_SENT*.
Sobald das SYN-Paket beim Server ankommt, bestätigt dieser es mit einem
SYN-ACK-Paket und geht in den Zustand *SYN_RCVD*.
Der Client bestätigt das SYN-ACK-Paket mit ACK und geht in den Zustand
*ESTABLISHED*.
Sobald das ACK-Paket beim Server ankommt geht dieser ebenfalls in den Zustand
*ESTABLISHED* und die Verbindung ist vollständig etabliert.

Nur bei den ersten beiden Datenpaketen kann man vom Netzwerk aus sehen, welche
Seite die Verbindung aktiv aufgebaut hat.

Wenn an dem betreffenden Port auf Serverseite kein Prozess lauscht oder der
Server eine Verbindung abweist, sieht das wie folgt aus:

XXX hier das Diagramm TCP-Reset einfügen

Der Client sendet wie eben ein SYN-Paket.
Von Serverseite aus folgt unmittelbar ein RST-Paket und schon ist es vorbei.

#### Verbindungsabbau

Während für den TCP-Verbindungsaufbau drei Datenpakete reichen, benötigt TCP
für den Abbau einer Verbindung vier Datenpakete.
Da sowohl Client als auch Server die Verbindung zuerst schließen können, nenne
ich die beteiligten Parteien hier A und B:

XXX hier das Diagram TCP-Verbindungsabbau einfügen

A schließt auf seiner Seite einseitig die TCP-Verbindung indem er ein
FIN-Paket sendet und geht in den Zustand *FIN_WAIT1*.
B bestätigt das FIN-Paket normal mit ACK und geht in den Zustand *CLOSE_WAIT*.
Jetzt könnte B noch Daten über die halbgeschlossene Verbindung senden, A
sendet nichts mehr.
Irgendwann sendet B ebenfalls ein FIN-Paket und geht in den Zustand *LAST_ACK*
über.
Sobald A das FIN-Paket empfängt, bestätigt es dieses mit ACK und geht für die
doppelte MSL in den Zustand *TIME_WAIT* und danach in den Zustand *CLOSED*.
B geht mit Empfang der Bestätigung von A sofort in den Zustand *CLOSED*.

Da A noch eine zeitlang im Zustand *TIME_WAIT* verbleibt, kann man auf dem
betreffenden Rechner mit `netstat -ant` sehen, dass dieser die Verbindung
zuerst geschlossen hat.

#### Flusssteuerung

Es gibt zwei Aspekte bei der TCP-Flusssteuerung.
Zum einen teilt der Empfänger dem Sender mit, wie viele Bytes er momentan
verarbeiten kann.
Zum anderen will der Sendeer die Datenrate so steuern, dass die Daten so
schnell wie möglich, aber mit möglichst geringen Verlusten durch Überlastung
der Verbindung übertragen werden.

Für das erste Problem gibt es im TCP-Header das Feld *Receive Window*.
In dieses trägt der Empfänger die momentan freie Empfangspuffergröße ein.
Ein *Receive Window* von 0 bringt die Datenübertragung zum Erliegen und deutet
darauf hin, dass der Empfänger die Daten nicht schnell genug verarbeiten kann.
Das kann ein Hinweis sein, bei Performanceproblemen die Situation auf dem
empfangenden Rechner in Augenschein zu nehmen.

Für die Flusssteuerung zur Vermeidung von Überlast gibt es verschiedene
Algorithmen, die gemeinsam verwendet werden können.
Der Sender führt für die Verbindung ein Congestion Window, das ihm anzeigt,
wieviel Bytes er momentan auf die Leitung schicken könnte.

##### Slow Start und Congestion Avoidance

Bei diesem Verfahren startet die Datenübertragung mit einem Congestion von
einer Maximum Segment Size (MSS) und erhöht diese mit jedem empfangenen ACK um
eine MSS.
Das führt zu einem exponentialen Wachstum des Congestion Windows.

Bei erreichen der *Slow Start Threshold* wird das Congestion Windows nur noch
um eine MSS erhöht, wenn alle Datenpakete aus dem aktuellen Fenster bestätigt
wurden. Das führt zu einem linearen Wachstum des Congestion Window.

Wird durch Timeout der Verlust eines Datenpakets festgestellt, beginnt dass
Congestion Window wieder bei einer MSS.

##### Fast Retransmit und Fast Recovery

Hierbei informiert der Empfänger den Sender über mögliche Paketverluste sobald
er Datenpakete außer der Reihe empfängt.
Dazu bestätigt er das letzte Datenpaket in der richtigen Reihenfolge mit jedem
neu ankommenden Datenpaket außer der Reihe durch sogenannte DUP-ACK (Duplicate
Acknowledgements).
Der Sender sendet das verlorene Datenpaket sofort nach dem driten DUP-ACK und
wartet nicht auf den Timeout.
Das Congestion Window wird in diesem Fall nur halbiert und nicht wie bei Slow
Start auf ein MSS reduziert.

##### Selective Acknowledgements (SACK)

Zusätzlich zum letzten regulären Paket bestätigt der Empfänger in den DUP-ACK
die außer der Reihe angekommenen Datenpakete in zusätzlichen
TCP-Headerfeldern, so dass diese nicht noch einmal gesendet werden müssen.

